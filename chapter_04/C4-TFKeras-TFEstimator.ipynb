{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_GCP_PROJECT_ID = \"bigquery-public-data\"\n",
    "DATASET_ID = 'covid19_geotab_mobility_impact'\n",
    "TABLE_ID = 'us_border_volumes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import feature_column\n",
    "from tensorflow_io.bigquery import BigQueryClient\n",
    "import numpy as np\n",
    "\n",
    "client = BigQueryClient()\n",
    "\n",
    "PROJECT_ID = \"project1-190517\" # A project ID in your GCP subscription.\n",
    "DATASET_GCP_PROJECT_ID = \"bigquery-public-data\"\n",
    "DATASET_ID = 'covid19_geotab_mobility_impact'\n",
    "TABLE_ID = 'us_border_volumes'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_session3 = client.read_session(\n",
    "   \"projects/\" + PROJECT_ID,\n",
    "   DATASET_GCP_PROJECT_ID, TABLE_ID, DATASET_ID,\n",
    "   [\"trip_direction\",\n",
    "    \"day_type\",\n",
    "    \"day_of_week\",\n",
    "    \"avg_crossing_duration\",\n",
    "    \"percent_of_normal_volume\",\n",
    "    \"avg_crossing_duration_truck\",\n",
    "    \"percent_of_normal_volume_truck\"\n",
    "   \n",
    "    ],\n",
    "   [tf.string,\n",
    "    tf.string,\n",
    "    tf.int64,\n",
    "    tf.double,\n",
    "    tf.int64,\n",
    "    tf.double,\n",
    "    tf.int64\n",
    "    ],\n",
    "     requested_streams=10\n",
    ")\n",
    "dataset3 = read_session3.parallel_read_rows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfrom_row(row_dict):\n",
    " \t# Identify column names for features.\n",
    " \tfeature_dict = { column:\n",
    "                 \t(tf.strings.strip(tensor) if tensor.dtype == 'string' else tensor)\n",
    "                 \tfor (column,tensor) in row_dict.items()\n",
    "                 \t}\n",
    " \t# Remove target column from data\n",
    " \ttarget = feature_dict.pop('avg_crossing_duration_truck')\n",
    " \t# Return a tuple of features and target\n",
    " \treturn (feature_dict, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_ds = dataset3.map(transfrom_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "SHUFFLE_BUFFER = 1024\n",
    "training_dataset3 = transformed_ds.shuffle(SHUFFLE_BUFFER).batch(BATCH_SIZE)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_categorical_feature_values(column):\n",
    "    query = 'SELECT DISTINCT TRIM({}) FROM `{}`.{}.{}'.format(column, DATASET_GCP_PROJECT_ID, DATASET_ID, TABLE_ID)\n",
    "    client = bigquery.Client(project=PROJECT_ID)\n",
    "    dataset_ref = client.dataset(DATASET_ID)\n",
    "    job_config = bigquery.QueryJobConfig()\n",
    "    query_job = client.query(query, job_config=job_config)\n",
    "    result = query_job.to_dataframe()\n",
    "    return result.values[:,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = []\n",
    "from google.cloud import bigquery\n",
    "# Numeric columns\n",
    "for header in ['day_of_week',     \n",
    "             'avg_crossing_duration',\n",
    "             'percent_of_normal_volume',\n",
    "             'percent_of_normal_volume_truck']:\n",
    " feature_columns.append(feature_column.numeric_column(header))\n",
    "\n",
    "# Categorical columns\n",
    "for header in ['trip_direction', 'day_type']:\n",
    " categorical_feature = feature_column.categorical_column_with_vocabulary_list(\n",
    "       header, get_categorical_feature_values(header))\n",
    " categorical_feature_one_hot = feature_column.indicator_column(categorical_feature)\n",
    " feature_columns.append(categorical_feature_one_hot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_layer = tf.keras.layers.DenseFeatures(feature_columns)\n",
    "Dense = tf.keras.layers.Dense\n",
    "\n",
    "model = tf.keras.Sequential(\n",
    " [\n",
    "   feature_layer,\n",
    "   Dense(100, activation=tf.nn.relu, kernel_initializer='uniform'),\n",
    "   Dense(75, activation=tf.nn.relu),\n",
    "   Dense(50, activation=tf.nn.relu),\n",
    "   Dense(25, activation=tf.nn.relu),\n",
    "   Dense(1)\n",
    " ])  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "   loss='mse',\n",
    "   metrics=['mae', 'mse'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/feature_column/feature_column_v2.py:4267: IndicatorColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/feature_column/feature_column_v2.py:4322: VocabularyListCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "Epoch 1/5\n",
      "29/29 [==============================] - 7s 226ms/step - loss: 85.6710 - mae: 6.6371 - mse: 86.8735\n",
      "Epoch 2/5\n",
      "29/29 [==============================] - 4s 151ms/step - loss: 24.0095 - mae: 3.5011 - mse: 24.5298\n",
      "Epoch 3/5\n",
      "29/29 [==============================] - 4s 150ms/step - loss: 9.0246 - mae: 2.0324 - mse: 8.9408\n",
      "Epoch 4/5\n",
      "29/29 [==============================] - 4s 155ms/step - loss: 7.0638 - mae: 1.5149 - mse: 7.1497\n",
      "Epoch 5/5\n",
      "29/29 [==============================] - 4s 144ms/step - loss: 7.2136 - mae: 1.9986 - mse: 7.2953\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f3b9ff9a0d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(training_dataset3, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples = {\n",
    "   'trip_direction' : np.array(['Mexico to US', 'US to Canada']),\n",
    "   'day_type' : np.array(['Weekdays', 'Weekends']),\n",
    "   'day_of_week' : np.array([4, 7]),\n",
    "   'avg_crossing_duration' : np.array([32.8, 10.4]),\n",
    "   'percent_of_normal_volume' : np.array([102, 89]),\n",
    "   'percent_of_normal_volume_truck' : np.array([106, 84])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[33.476192],\n",
       "       [11.808698]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(test_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow Estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow_io.bigquery import BigQueryClient\n",
    "from tensorflow import feature_column\n",
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime, os\n",
    "import itertools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = \"project1-190517\"\n",
    "DATASET_GCP_PROJECT_ID = \"bigquery-public-data\"\n",
    "DATASET_ID = 'covid19_geotab_mobility_impact'\n",
    "TABLE_ID = 'us_border_volumes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn():\n",
    " PROJECT_ID = \"project1-190517\" # This is from what you created in your Google Cloud Account.\n",
    " DATASET_GCP_PROJECT_ID = \"bigquery-public-data\"\n",
    " TABLE_ID = 'us_border_volumes'\n",
    " DATASET_ID = 'covid19_geotab_mobility_impact'  \n",
    " client = BigQueryClient()\n",
    " read_session = client.read_session(\n",
    "   \"projects/\" + PROJECT_ID,\n",
    "   DATASET_GCP_PROJECT_ID, TABLE_ID, DATASET_ID,\n",
    "   [\"trip_direction\",\n",
    "    \"day_type\",\n",
    "    \"day_of_week\",\n",
    "    \"avg_crossing_duration\",\n",
    "    \"percent_of_normal_volume\",\n",
    "    \"avg_crossing_duration_truck\",\n",
    "    \"percent_of_normal_volume_truck\"\n",
    "   \n",
    "    ],\n",
    "   [tf.string,\n",
    "    tf.string,\n",
    "    tf.int64,\n",
    "    tf.double,\n",
    "    tf.int64,\n",
    "    tf.double,\n",
    "    tf.int64\n",
    "    ],\n",
    "     requested_streams=10\n",
    "   )\n",
    " dataset = read_session.parallel_read_rows()\n",
    "\n",
    " def transfrom_row(row_dict):\n",
    "   # Trim all string tensors\n",
    "   feature_dict = { column:\n",
    "                   (tf.strings.strip(tensor) if tensor.dtype == 'string' else tensor)\n",
    "                   for (column,tensor) in row_dict.items()\n",
    "                   }\n",
    "   # Extract target from features\n",
    "   target = feature_dict.pop('avg_crossing_duration_truck')\n",
    "   # return a tuple of features and target\n",
    "   return (feature_dict, target)\n",
    "\n",
    " transformed_ds = dataset.map(transfrom_row)\n",
    " transformed_ds = transformed_ds.batch(32)\n",
    "\n",
    " return transformed_ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = []\n",
    "# Numeric columns\n",
    "for header in ['day_of_week',     \n",
    "             'avg_crossing_duration',\n",
    "             'percent_of_normal_volume',\n",
    "             'percent_of_normal_volume_truck']:\n",
    " feature_columns.append(feature_column.numeric_column(header))\n",
    "\n",
    "# Categorical columns\n",
    "for header in ['trip_direction', 'day_type']:\n",
    " categorical_feature = feature_column.categorical_column_with_vocabulary_list(\n",
    "       header, get_categorical_feature_values(header))\n",
    " categorical_feature_one_hot = feature_column.indicator_column(categorical_feature)\n",
    " feature_columns.append(categorical_feature_one_hot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NumericColumn(key='day_of_week', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='avg_crossing_duration', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='percent_of_normal_volume', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='percent_of_normal_volume_truck', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='trip_direction', vocabulary_list=('US to Canada', 'US to Mexico', 'Canada to US', 'Mexico to US'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='day_type', vocabulary_list=('Weekends', 'Weekdays'), dtype=tf.string, default_value=-1, num_oov_buckets=0))]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = os.path.join(\"models\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘models’: File exists\n"
     ]
    }
   ],
   "source": [
    "%mkdir models\n",
    "%mkdir {MODEL_DIR}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'models/20201029-033738', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer linear/linear_model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/feature_column/feature_column_v2.py:518: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/optimizer_v2/ftrl.py:143: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into models/20201029-033738/model.ckpt.\n",
      "INFO:tensorflow:loss = 364.4175, step = 0\n",
      "INFO:tensorflow:Saving checkpoints for 29 into models/20201029-033738/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 9.172665.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.linear.LinearRegressorV2 at 0x7f3b9402ddd0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_est = tf.estimator.LinearRegressor(feature_columns=feature_columns, model_dir=MODEL_DIR)\n",
    "linear_est.train(input_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples = {\n",
    "   'trip_direction' : np.array(['Mexico to US', 'US to Canada']),\n",
    "   'day_type' : np.array(['Weekdays', 'Weekends']),\n",
    "   'day_of_week' : np.array([4, 7]),\n",
    "   'avg_crossing_duration' : np.array([32.8, 10.4]),\n",
    "   'percent_of_normal_volume' : np.array([102, 89]),\n",
    "   'percent_of_normal_volume_truck' : np.array([106, 84])\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring_input_fn():\n",
    " return tf.data.Dataset.from_tensor_slices(test_samples).batch(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = linear_est.predict(   \n",
    "        input_fn=scoring_input_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer linear/linear_model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from models/20201029-033738/model.ckpt-29\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "Predictions: [array([26.892534], dtype=float32), array([12.188314], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "predictions = list(p[\"predictions\"] for p in itertools.islice(y, 2))\n",
    "print(\"Predictions: {}\".format(str(predictions)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-1.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m46"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
