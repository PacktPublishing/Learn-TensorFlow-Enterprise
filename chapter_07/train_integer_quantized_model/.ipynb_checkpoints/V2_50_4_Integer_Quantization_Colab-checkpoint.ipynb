{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kaxfRx4ghAA5",
    "outputId": "78606c07-4768-488e-c8c3-d836ac2fe476"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-model-optimization in /usr/local/lib/python3.6/dist-packages (0.5.0)\n",
      "Requirement already satisfied: numpy~=1.14 in /usr/local/lib/python3.6/dist-packages (from tensorflow-model-optimization) (1.18.5)\n",
      "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-model-optimization) (0.1.5)\n",
      "Requirement already satisfied: six~=1.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow-model-optimization) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-model-optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aqtov3buhFgG",
    "outputId": "ed46a551-0dd9-4d88-f5ce-12cab0c199aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "id": "9U0_rhozhI_a"
   },
   "outputs": [],
   "source": [
    "# Authenticate to GCS.\n",
    "from google.colab import auth\n",
    "auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TWg7vY3qhLe8",
    "outputId": "b524133b-63b3-44c7-cdf2-9cfa930a879d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r",
      "100   653  100   653    0     0  21766      0 --:--:-- --:--:-- --:--:-- 21766\n",
      "OK\n",
      "13 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
      "gcsfuse is already the newest version (0.32.0).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 13 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "!echo \"deb http://packages.cloud.google.com/apt gcsfuse-bionic main\" > /etc/apt/sources.list.d/gcsfuse.list\n",
    "!curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -\n",
    "!apt -qq update\n",
    "!apt -qq install gcsfuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rWb1cJy5hUrL",
    "outputId": "1b4af3b0-77ff-4f94-ba99-c9f82adb5ae6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘tfrecord-dataset’: File exists\n",
      "Using mount point: /content/tfrecord-dataset\n",
      "Opening GCS connection...\n",
      "Mounting file system...\n",
      "File system has been successfully mounted.\n"
     ]
    }
   ],
   "source": [
    "!mkdir tfrecord-dataset\n",
    "!gcsfuse --implicit-dirs tfrecord-dataset /content/tfrecord-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_MM1_0p8hZkg",
    "outputId": "8ef476b1-b57c-48bb-f9d7-cf8350605f95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom_cnn\n",
      "dataset_info.json\n",
      "full_model\n",
      "image_classification_builder-test.tfrecord-00000-of-00001\n",
      "image_classification_builder-train.tfrecord-00000-of-00002\n",
      "image_classification_builder-train.tfrecord-00001-of-00002\n",
      "image_classification_builder-validation.tfrecord-00000-of-00001\n",
      "image-encoded.image.json\n",
      "quantized_resnet_vector\n"
     ]
    }
   ],
   "source": [
    "!ls /content/tfrecord-dataset/flowers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "kFT_pDYghbtK"
   },
   "outputs": [],
   "source": [
    "root_dir = '../train_base_model/tf_datasets/flower_photos'\n",
    "file_pattern = \"{}/image_classification_builder-train*.tfrecord*\".format(root_dir)\n",
    "val_file_pattern = \"{}/image_classification_builder-validation*.tfrecord*\".format(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "PVsmBp3dheis"
   },
   "outputs": [],
   "source": [
    "file_list = tf.io.gfile.glob(file_pattern)\n",
    "all_files = tf.data.Dataset.list_files( tf.io.gfile.glob(file_pattern))\n",
    "\n",
    "val_file_list = tf.io.gfile.glob(val_file_pattern)\n",
    "val_all_files = tf.data.Dataset.list_files( tf.io.gfile.glob(val_file_pattern))\n",
    "\n",
    "train_all_ds = tf.data.TFRecordDataset(all_files, num_parallel_reads=tf.data.experimental.AUTOTUNE)\n",
    "val_all_ds = tf.data.TFRecordDataset(val_all_files, num_parallel_reads=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "lmLfUUcChgyj"
   },
   "outputs": [],
   "source": [
    "def decode_and_resize(serialized_example):\n",
    "    # resized image should be [224, 224, 3] and normalized to value range [0, 255] \n",
    "    # label is integer index of class.\n",
    "    \n",
    "    parsed_features = tf.io.parse_single_example(\n",
    "    serialized_example,\n",
    "    features = {\n",
    "    'image/channels' :  tf.io.FixedLenFeature([], tf.int64),\n",
    "    'image/class/label' :  tf.io.FixedLenFeature([], tf.int64),\n",
    "    'image/class/text' : tf.io.FixedLenFeature([], tf.string),\n",
    "    'image/colorspace' : tf.io.FixedLenFeature([], tf.string),\n",
    "    'image/encoded' : tf.io.FixedLenFeature([], tf.string),\n",
    "    'image/filename' : tf.io.FixedLenFeature([], tf.string),\n",
    "    'image/format' : tf.io.FixedLenFeature([], tf.string),\n",
    "    'image/height' : tf.io.FixedLenFeature([], tf.int64),\n",
    "    'image/width' : tf.io.FixedLenFeature([], tf.int64)\n",
    "    })\n",
    "    image = tf.io.decode_jpeg(parsed_features['image/encoded'], channels=3)\n",
    "    label = tf.cast(parsed_features['image/class/label'], tf.int32)\n",
    "    label_txt = tf.cast(parsed_features['image/class/text'], tf.string)\n",
    "    label_one_hot = tf.one_hot(label, depth = 5)\n",
    "    resized_image = tf.image.resize(image, [224, 224], method='nearest')\n",
    "    return resized_image, label_one_hot\n",
    "\n",
    "def normalize(image, label):\n",
    "    #Convert `image` from [0, 255] -> [0, 1.0] floats \n",
    "    image = tf.cast(image, tf.float32) / 255. + 0.5\n",
    "    return image, label\n",
    "\n",
    "def prepare_for_training(ds, cache=True, shuffle_buffer_size=1000):\n",
    "    # This is a small dataset, only load it once, and keep it in memory.\n",
    "    # use `.cache(filename)` to cache preprocessing work for datasets that don't\n",
    "    # fit in memory.\n",
    "\n",
    "    if cache:\n",
    "        if isinstance(cache, str):\n",
    "            ds = ds.cache(cache)\n",
    "        else:\n",
    "            ds = ds.cache()\n",
    "\n",
    "    ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
    "    # Repeat forever\n",
    "    ds = ds.repeat()\n",
    "    ds = ds.batch(32)\n",
    "    # `prefetch` lets the dataset fetch batches in the background while the model\n",
    "    # is training.\n",
    "    AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "    ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Oc8CKnNXhnQ9"
   },
   "outputs": [],
   "source": [
    "# perform data engineering \n",
    "dataset = train_all_ds.map(decode_and_resize)\n",
    "val_dataset = val_all_ds.map(decode_and_resize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "CUSbDz4xhpy-"
   },
   "outputs": [],
   "source": [
    "# Create dataset for training run\n",
    "BATCH_SIZE = 32\n",
    "VALIDATION_BATCH_SIZE = 40\n",
    "dataset = dataset.map(normalize, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "val_dataset = val_dataset.map(normalize, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "val_ds = val_dataset.batch(VALIDATION_BATCH_SIZE)\n",
    "    \n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "train_ds = prepare_for_training(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GNCkQOXFhrM5",
    "outputId": "3f276f22-9b1a-4ac5-98c2-2cc6481e1c30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_SAMPLE_SIZE =  3540\n",
      "VALIDATION_SAMPLE_SIZE =  80\n"
     ]
    }
   ],
   "source": [
    "NUM_CLASSES = 5\n",
    "IMAGE_SIZE = (224, 224)\n",
    "    \n",
    "train_sample_size=0\n",
    "for raw_record in train_all_ds:\n",
    "    train_sample_size += 1\n",
    "print('TRAIN_SAMPLE_SIZE = ', train_sample_size)\n",
    "validation_sample_size=0\n",
    "for raw_record in val_all_ds:\n",
    "    validation_sample_size += 1\n",
    "print('VALIDATION_SAMPLE_SIZE = ', validation_sample_size)\n",
    "\n",
    "STEPS_PER_EPOCHS = train_sample_size // BATCH_SIZE\n",
    "VALIDATION_STEPS = validation_sample_size // VALIDATION_BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "id": "SdYqNE-Hht_d"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "model = tf.keras.Sequential([\n",
    "        #tf.keras.layers.InputLayer(input_shape=IMAGE_SIZE + (3,)),\n",
    "        tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu', \n",
    "                           kernel_initializer='he_uniform', padding='same', input_shape =IMAGE_SIZE + (3,)),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(256, activation='relu', kernel_initializer='glorot_uniform'),\n",
    "        tf.keras.layers.Dense(NUM_CLASSES, activation='softmax', name = 'custom_class')\n",
    "    ])\n",
    "'''\n",
    "import tensorflow_hub as hub\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape=IMAGE_SIZE + (3,)),\n",
    "    #hub.KerasLayer(MODULE_HANDLE, trainable=FINE_TUNING_CHOICE),\n",
    "    #hub.KerasLayer(\"https://tfhub.dev/tensorflow/resnet_50/feature_vector/1\", trainable=FINE_TUNING_CHOICE), \n",
    "    hub.KerasLayer(\"https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/4\",\n",
    "                   trainable=False),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(units = 64, activation = 'relu', kernel_initializer='glorot_uniform'),\n",
    "    tf.keras.layers.Dense(NUM_CLASSES, activation='softmax', name = 'custom_class')\n",
    "])\n",
    "\n",
    "model.build([None, 224, 224, 3])\n",
    "\n",
    "model.compile(\n",
    "  optimizer=tf.keras.optimizers.SGD(lr=0.005, momentum=0.9), \n",
    "  loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True, label_smoothing=0.1),\n",
    "  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jo2JOl1ehweQ",
    "outputId": "9fbb14cc-145b-43e2-d3cb-d4fe1b57f0ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "keras_layer_2 (KerasLayer)   (None, 2048)              23564800  \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                131136    \n",
      "_________________________________________________________________\n",
      "custom_class (Dense)         (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 23,696,261\n",
      "Trainable params: 131,461\n",
      "Non-trainable params: 23,564,800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "id": "herMqp_KhzEA"
   },
   "outputs": [],
   "source": [
    "decoded = val_all_ds.map(decode_and_resize)\n",
    "normed = decoded.map(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "id": "bWxr3qyGiiND"
   },
   "outputs": [],
   "source": [
    "np_img_holder = np.empty((0, 224, 224,3), float)\n",
    "np_lbl_holder = np.empty((0, 5), int)\n",
    "for img, lbl in normed:\n",
    "    r = img.numpy() # image value extracted\n",
    "    rx = np.expand_dims(r, axis=0) # expand by adding a dimension for batching images.\n",
    "    lx = np.expand_dims(lbl, axis=0) # expand by adding a dimension for batching labels.\n",
    "    np_img_holder = np.append(np_img_holder, rx, axis=0) # append each image to create a batch of images.\n",
    "    np_lbl_holder = np.append(np_lbl_holder, lx, axis=0) # append each one-hot label to create a batch of labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GdSle3bbzvHi",
    "outputId": "0733690d-f9dc-45d0-ac09-2d56ab0ca8cd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[1.3039216 , 0.5352941 , 0.6215686 ],\n",
       "         [1.2921569 , 0.5117647 , 0.6333333 ],\n",
       "         [1.3352941 , 0.5470588 , 0.68039215],\n",
       "         ...,\n",
       "         [1.1117647 , 0.982353  , 1.009804  ],\n",
       "         [1.0058824 , 0.8843137 , 0.9078431 ],\n",
       "         [0.71960783, 0.55490196, 0.59411764]],\n",
       "\n",
       "        [[1.2686274 , 0.5117647 , 0.57843137],\n",
       "         [1.2568628 , 0.5       , 0.60588235],\n",
       "         [1.3039216 , 0.53137255, 0.6490196 ],\n",
       "         ...,\n",
       "         [1.0647058 , 0.93529415, 0.9627451 ],\n",
       "         [1.0607843 , 0.93921566, 0.9627451 ],\n",
       "         [0.82941175, 0.6843137 , 0.71568626]],\n",
       "\n",
       "        [[1.2411765 , 0.5156863 , 0.5470588 ],\n",
       "         [1.2176471 , 0.50784314, 0.5745098 ],\n",
       "         [1.2568628 , 0.527451  , 0.6098039 ],\n",
       "         ...,\n",
       "         [1.0254903 , 0.9       , 0.9196079 ],\n",
       "         [0.95490193, 0.8333334 , 0.8568628 ],\n",
       "         [0.88823533, 0.76666665, 0.7980392 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.5862745 , 0.64117646, 0.5392157 ],\n",
       "         [0.7705883 , 0.6607843 , 0.64509803],\n",
       "         [1.0137255 , 0.7784314 , 0.82549024],\n",
       "         ...,\n",
       "         [1.017647  , 0.5862745 , 0.5901961 ],\n",
       "         [1.0019608 , 0.6098039 , 0.6098039 ],\n",
       "         [0.9       , 0.6333333 , 0.62941176]],\n",
       "\n",
       "        [[0.5509804 , 0.5862745 , 0.5       ],\n",
       "         [0.8137255 , 0.66862744, 0.7       ],\n",
       "         [1.0333333 , 0.7588235 , 0.8607843 ],\n",
       "         ...,\n",
       "         [1.0019608 , 0.5470588 , 0.5588235 ],\n",
       "         [0.9470588 , 0.53137255, 0.5470588 ],\n",
       "         [0.87254906, 0.53137255, 0.56666666]],\n",
       "\n",
       "        [[0.56666666, 0.5901961 , 0.5       ],\n",
       "         [0.8411765 , 0.68039215, 0.74313724],\n",
       "         [1.017647  , 0.7235294 , 0.845098  ],\n",
       "         ...,\n",
       "         [1.0215687 , 0.5470588 , 0.56666666],\n",
       "         [0.9509804 , 0.5156863 , 0.5392157 ],\n",
       "         [0.8686274 , 0.5       , 0.5470588 ]]],\n",
       "\n",
       "\n",
       "       [[[1.4843137 , 1.5       , 1.4803922 ],\n",
       "         [1.4843137 , 1.5       , 1.4803922 ],\n",
       "         [1.4843137 , 1.5       , 1.4803922 ],\n",
       "         ...,\n",
       "         [1.4686275 , 1.154902  , 1.1980393 ],\n",
       "         [1.4607843 , 1.1588235 , 1.182353  ],\n",
       "         [1.4568627 , 1.182353  , 1.182353  ]],\n",
       "\n",
       "        [[1.4843137 , 1.5       , 1.4803922 ],\n",
       "         [1.4843137 , 1.5       , 1.4803922 ],\n",
       "         [1.4843137 , 1.5       , 1.4803922 ],\n",
       "         ...,\n",
       "         [1.4607843 , 1.1588235 , 1.1980393 ],\n",
       "         [1.464706  , 1.1705883 , 1.1980393 ],\n",
       "         [1.4372549 , 1.1666667 , 1.1784314 ]],\n",
       "\n",
       "        [[1.4921569 , 1.5       , 1.4882352 ],\n",
       "         [1.4921569 , 1.5       , 1.4882352 ],\n",
       "         [1.4882352 , 1.4960785 , 1.4843137 ],\n",
       "         ...,\n",
       "         [1.445098  , 1.1470588 , 1.1862745 ],\n",
       "         [1.4411764 , 1.154902  , 1.190196  ],\n",
       "         [1.472549  , 1.2137256 , 1.2529411 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1.3666667 , 1.1235294 , 1.3078432 ],\n",
       "         [1.3745098 , 1.1392157 , 1.3392158 ],\n",
       "         [1.3705883 , 1.1431372 , 1.3392158 ],\n",
       "         ...,\n",
       "         [1.1470588 , 0.78627455, 0.80588233],\n",
       "         [1.1627451 , 0.8019608 , 0.8215686 ],\n",
       "         [1.1627451 , 0.8019608 , 0.8137255 ]],\n",
       "\n",
       "        [[1.362745  , 1.1156863 , 1.2921569 ],\n",
       "         [1.3784313 , 1.1352942 , 1.327451  ],\n",
       "         [1.3745098 , 1.1431372 , 1.3313725 ],\n",
       "         ...,\n",
       "         [1.1862745 , 0.8215686 , 0.8647059 ],\n",
       "         [1.1784314 , 0.8137255 , 0.85294116],\n",
       "         [1.154902  , 0.7941177 , 0.8137255 ]],\n",
       "\n",
       "        [[1.3745098 , 1.127451  , 1.2960784 ],\n",
       "         [1.3745098 , 1.1313726 , 1.3156862 ],\n",
       "         [1.3784313 , 1.1352942 , 1.327451  ],\n",
       "         ...,\n",
       "         [1.2137256 , 0.845098  , 0.9078431 ],\n",
       "         [1.1862745 , 0.8215686 , 0.8647059 ],\n",
       "         [1.1627451 , 0.7980392 , 0.82941175]]],\n",
       "\n",
       "\n",
       "       [[[0.7       , 0.82549024, 0.76666665],\n",
       "         [0.6882353 , 0.80980396, 0.7470588 ],\n",
       "         [0.68039215, 0.8019608 , 0.7392157 ],\n",
       "         ...,\n",
       "         [0.71568626, 0.80588233, 0.5       ],\n",
       "         [0.69215685, 0.7980392 , 0.5       ],\n",
       "         [0.7078431 , 0.8333334 , 0.5352941 ]],\n",
       "\n",
       "        [[0.68039215, 0.8019608 , 0.74313724],\n",
       "         [0.64509803, 0.76666665, 0.70392156],\n",
       "         [0.64117646, 0.7509804 , 0.69215685],\n",
       "         ...,\n",
       "         [0.7509804 , 0.8411765 , 0.527451  ],\n",
       "         [0.7470588 , 0.8411765 , 0.5352941 ],\n",
       "         [0.7117647 , 0.8333334 , 0.51960784]],\n",
       "\n",
       "        [[0.64117646, 0.7509804 , 0.69215685],\n",
       "         [0.6098039 , 0.71960783, 0.6647059 ],\n",
       "         [0.60588235, 0.7078431 , 0.65686274],\n",
       "         ...,\n",
       "         [0.7745098 , 0.8607843 , 0.5352941 ],\n",
       "         [0.7823529 , 0.87254906, 0.5509804 ],\n",
       "         [0.73137254, 0.84901965, 0.5117647 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.5509804 , 0.5745098 , 0.5352941 ],\n",
       "         [0.5392157 , 0.56666666, 0.5352941 ],\n",
       "         [0.5235294 , 0.5509804 , 0.5235294 ],\n",
       "         ...,\n",
       "         [0.7588235 , 0.8411765 , 0.71960783],\n",
       "         [0.754902  , 0.845098  , 0.74313724],\n",
       "         [0.65294117, 0.74313724, 0.68039215]],\n",
       "\n",
       "        [[0.5392157 , 0.5627451 , 0.5156863 ],\n",
       "         [0.54313725, 0.5627451 , 0.5352941 ],\n",
       "         [0.5352941 , 0.55490196, 0.53137255],\n",
       "         ...,\n",
       "         [0.7078431 , 0.79019606, 0.6607843 ],\n",
       "         [0.70392156, 0.7980392 , 0.6960784 ],\n",
       "         [0.6490196 , 0.76274514, 0.6843137 ]],\n",
       "\n",
       "        [[0.53137255, 0.55490196, 0.5       ],\n",
       "         [0.5509804 , 0.5745098 , 0.5352941 ],\n",
       "         [0.54313725, 0.5627451 , 0.5392157 ],\n",
       "         ...,\n",
       "         [0.64117646, 0.7235294 , 0.59411764],\n",
       "         [0.64117646, 0.7392157 , 0.6254902 ],\n",
       "         [0.6333333 , 0.7588235 , 0.66862744]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[1.0137255 , 1.182353  , 1.4882352 ],\n",
       "         [1.0137255 , 1.182353  , 1.4882352 ],\n",
       "         [1.0137255 , 1.182353  , 1.4882352 ],\n",
       "         ...,\n",
       "         [0.97843134, 1.1431372 , 1.4411764 ],\n",
       "         [0.97843134, 1.1431372 , 1.4411764 ],\n",
       "         [0.97450984, 1.1392157 , 1.4372549 ]],\n",
       "\n",
       "        [[1.017647  , 1.1862745 , 1.4921569 ],\n",
       "         [1.017647  , 1.1862745 , 1.4921569 ],\n",
       "         [1.017647  , 1.1862745 , 1.4921569 ],\n",
       "         ...,\n",
       "         [0.97843134, 1.1431372 , 1.4411764 ],\n",
       "         [0.97843134, 1.1431372 , 1.4411764 ],\n",
       "         [0.97450984, 1.1392157 , 1.4372549 ]],\n",
       "\n",
       "        [[1.017647  , 1.190196  , 1.4843137 ],\n",
       "         [1.017647  , 1.190196  , 1.4843137 ],\n",
       "         [1.017647  , 1.190196  , 1.4843137 ],\n",
       "         ...,\n",
       "         [0.97843134, 1.1392157 , 1.4490197 ],\n",
       "         [0.97843134, 1.1392157 , 1.4490197 ],\n",
       "         [0.97843134, 1.1392157 , 1.4490197 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1.1470588 , 1.2215686 , 0.76666665],\n",
       "         [1.1196079 , 1.2019608 , 0.70392156],\n",
       "         [1.1196079 , 1.2019608 , 0.70392156],\n",
       "         ...,\n",
       "         [1.0529412 , 1.1392157 , 0.99803925],\n",
       "         [1.0529412 , 1.1392157 , 0.99803925],\n",
       "         [0.91568625, 1.0215687 , 0.9470588 ]],\n",
       "\n",
       "        [[1.1039217 , 1.1862745 , 0.64117646],\n",
       "         [1.1       , 1.1862745 , 0.61764705],\n",
       "         [1.1       , 1.1862745 , 0.61764705],\n",
       "         ...,\n",
       "         [0.88823533, 0.97843134, 0.9078431 ],\n",
       "         [0.88823533, 0.97843134, 0.9078431 ],\n",
       "         [0.8372549 , 0.9470588 , 0.9627451 ]],\n",
       "\n",
       "        [[1.1509805 , 1.2411765 , 0.64509803],\n",
       "         [1.1235294 , 1.2137256 , 0.6137255 ],\n",
       "         [1.1235294 , 1.2137256 , 0.6137255 ],\n",
       "         ...,\n",
       "         [0.7784314 , 0.8686274 , 0.82941175],\n",
       "         [0.7784314 , 0.8686274 , 0.82941175],\n",
       "         [0.8686274 , 0.982353  , 1.0450981 ]]],\n",
       "\n",
       "\n",
       "       [[[1.3509804 , 1.4098039 , 1.0764706 ],\n",
       "         [1.2529411 , 1.327451  , 1.2098039 ],\n",
       "         [1.2529411 , 1.3392158 , 1.2882353 ],\n",
       "         ...,\n",
       "         [1.2411765 , 1.354902  , 1.2843137 ],\n",
       "         [1.2450981 , 1.3509804 , 1.2137256 ],\n",
       "         [1.3196079 , 1.4176471 , 1.0607843 ]],\n",
       "\n",
       "        [[1.2294118 , 1.2960784 , 1.0294118 ],\n",
       "         [0.845098  , 0.9235294 , 0.87647057],\n",
       "         [0.8333334 , 0.927451  , 0.9431373 ],\n",
       "         ...,\n",
       "         [0.78627455, 0.9039216 , 0.9039216 ],\n",
       "         [0.8607843 , 0.9666667 , 0.9       ],\n",
       "         [1.2137256 , 1.3039216 , 1.0215687 ]],\n",
       "\n",
       "        [[1.2686274 , 1.3509804 , 1.2215686 ],\n",
       "         [0.9666667 , 1.0647058 , 1.1509805 ],\n",
       "         [0.927451  , 1.0372549 , 1.190196  ],\n",
       "         ...,\n",
       "         [0.927451  , 1.0450981 , 1.1941177 ],\n",
       "         [0.93529415, 1.0411766 , 1.1235294 ],\n",
       "         [1.2294118 , 1.3235295 , 1.190196  ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1.2529411 , 1.3980392 , 1.2647059 ],\n",
       "         [1.0411766 , 1.1627451 , 1.3470588 ],\n",
       "         [1.017647  , 1.1313726 , 1.4294118 ],\n",
       "         ...,\n",
       "         [0.9941176 , 1.0803921 , 1.0294118 ],\n",
       "         [1.1156863 , 1.2058823 , 1.1745098 ],\n",
       "         [1.2803922 , 1.3745098 , 1.272549  ]],\n",
       "\n",
       "        [[1.1941177 , 1.3078432 , 1.0803921 ],\n",
       "         [1.0450981 , 1.1392157 , 1.1392157 ],\n",
       "         [1.0294118 , 1.1196079 , 1.190196  ],\n",
       "         ...,\n",
       "         [0.95490193, 1.0254903 , 0.7980392 ],\n",
       "         [1.2176471 , 1.2960784 , 1.0960784 ],\n",
       "         [1.2333333 , 1.3196079 , 1.0686275 ]],\n",
       "\n",
       "        [[1.4098039 , 1.4372549 , 1.0294118 ],\n",
       "         [1.327451  , 1.3588235 , 0.9627451 ],\n",
       "         [1.327451  , 1.3705883 , 0.9705882 ],\n",
       "         ...,\n",
       "         [1.2215686 , 1.2647059 , 0.76274514],\n",
       "         [1.3156862 , 1.3745098 , 0.8843137 ],\n",
       "         [1.362745  , 1.4254901 , 0.9078431 ]]],\n",
       "\n",
       "\n",
       "       [[[0.9196079 , 0.9235294 , 0.8607843 ],\n",
       "         [0.9078431 , 0.91176474, 0.8568628 ],\n",
       "         [0.9313725 , 0.9313725 , 0.8843137 ],\n",
       "         ...,\n",
       "         [0.8568628 , 0.8568628 , 0.8176471 ],\n",
       "         [0.8568628 , 0.8607843 , 0.8372549 ],\n",
       "         [0.82941175, 0.8411765 , 0.8137255 ]],\n",
       "\n",
       "        [[0.89215684, 0.89607847, 0.8333334 ],\n",
       "         [0.91568625, 0.9196079 , 0.8647059 ],\n",
       "         [0.91176474, 0.91176474, 0.8647059 ],\n",
       "         ...,\n",
       "         [0.85294116, 0.85294116, 0.8215686 ],\n",
       "         [0.845098  , 0.84901965, 0.8176471 ],\n",
       "         [0.845098  , 0.85294116, 0.80980396]],\n",
       "\n",
       "        [[0.91176474, 0.91568625, 0.8607843 ],\n",
       "         [0.91176474, 0.91176474, 0.8647059 ],\n",
       "         [0.927451  , 0.927451  , 0.8803922 ],\n",
       "         ...,\n",
       "         [0.8568628 , 0.85294116, 0.8372549 ],\n",
       "         [0.85294116, 0.84901965, 0.82941175],\n",
       "         [0.8568628 , 0.85294116, 0.8333334 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1.0254903 , 1.0294118 , 0.97450984],\n",
       "         [1.0019608 , 1.009804  , 0.9666667 ],\n",
       "         [0.97843134, 0.9901961 , 0.9627451 ],\n",
       "         ...,\n",
       "         [0.8137255 , 0.8137255 , 0.76666665],\n",
       "         [0.8019608 , 0.8019608 , 0.76274514],\n",
       "         [0.80588233, 0.8137255 , 0.7705883 ]],\n",
       "\n",
       "        [[1.0607843 , 1.0529412 , 1.0019608 ],\n",
       "         [1.0215687 , 1.0215687 , 0.982353  ],\n",
       "         [0.99803925, 1.009804  , 0.982353  ],\n",
       "         ...,\n",
       "         [0.84901965, 0.84901965, 0.8019608 ],\n",
       "         [0.845098  , 0.845098  , 0.80588233],\n",
       "         [0.84901965, 0.85294116, 0.8215686 ]],\n",
       "\n",
       "        [[1.0921569 , 1.0843138 , 1.0333333 ],\n",
       "         [1.0411766 , 1.0411766 , 1.0019608 ],\n",
       "         [1.017647  , 1.0294118 , 0.9941176 ],\n",
       "         ...,\n",
       "         [0.87254906, 0.87254906, 0.8333334 ],\n",
       "         [0.87647057, 0.87647057, 0.845098  ],\n",
       "         [0.8647059 , 0.87647057, 0.84901965]]]], dtype=float32)"
      ]
     },
     "execution_count": 331,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_img_holder.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "id": "Bd4-CrMAh3BD"
   },
   "outputs": [],
   "source": [
    "checkpoint_prefix = os.path.join('/content/trained_resnet_vector', \"train_ckpt_{epoch}\")\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.TensorBoard(log_dir=os.path.join('/content/trained_resnet_vector', 'tensorboard_logs')),\n",
    "    tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wWfusFRbh8c5",
    "outputId": "b3bc5db6-46c1-482a-a4bf-3aa6f1d6a829"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "  2/110 [..............................] - ETA: 28s - loss: 1.6845 - accuracy: 0.0625WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1046s vs `on_train_batch_end` time: 0.4139s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1046s vs `on_train_batch_end` time: 0.4139s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 14s 126ms/step - loss: 1.3490 - accuracy: 0.5875 - val_loss: 1.2192 - val_accuracy: 0.7750\n",
      "Epoch 2/5\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 1.1576 - accuracy: 0.8270 - val_loss: 1.1546 - val_accuracy: 0.8250\n",
      "Epoch 3/5\n",
      "110/110 [==============================] - 11s 103ms/step - loss: 1.1182 - accuracy: 0.8659 - val_loss: 1.1320 - val_accuracy: 0.8500\n",
      "Epoch 4/5\n",
      "110/110 [==============================] - 12s 105ms/step - loss: 1.1012 - accuracy: 0.8861 - val_loss: 1.1387 - val_accuracy: 0.8500\n",
      "Epoch 5/5\n",
      "110/110 [==============================] - 11s 103ms/step - loss: 1.0862 - accuracy: 0.9040 - val_loss: 1.1255 - val_accuracy: 0.8625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd61b23f4a8>"
      ]
     },
     "execution_count": 298,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "        train_ds,\n",
    "        epochs=5, \n",
    "        steps_per_epoch=STEPS_PER_EPOCHS,\n",
    "        validation_data=val_ds,\n",
    "        validation_steps=VALIDATION_STEPS,\n",
    "        callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mzcQQZ6ulP3p"
   },
   "source": [
    "## Saving original model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1WqC1VJbkti6",
    "outputId": "65bc7b64-a44c-411a-87ff-f983aa2b1695"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /content/tfrecord-dataset/flowers/full_model/full_resnet_vector_saved_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /content/tfrecord-dataset/flowers/full_model/full_resnet_vector_saved_model/assets\n"
     ]
    }
   ],
   "source": [
    "saved_model_path = os.path.join(root_dir, 'full_model/full_resnet_vector_saved_model')\n",
    "tf.saved_model.save(model, saved_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "erSca3fblx1h",
    "outputId": "58e403be-fffd-4aa6-e328-6a44b771468e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content/tfrecord-dataset/flowers/full_model/full_resnet_vector_saved_model'"
      ]
     },
     "execution_count": 300,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gfqBysRNlkm4",
    "outputId": "6a7aef7c-5484-4028-ae37-6e7612cee724"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 93187\n",
      "-rw-r--r-- 1 root root 95401506 Oct 31 22:30 variables.data-00000-of-00001\n",
      "-rw-r--r-- 1 root root    20947 Oct 31 22:30 variables.index\n"
     ]
    }
   ],
   "source": [
    "!ls -lrt /content/tfrecord-dataset/flowers/full_model/full_resnet_vector_saved_model/variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "id": "VG9ViyIIiZop"
   },
   "outputs": [],
   "source": [
    "\n",
    "def data_generator():\n",
    "  for input_tensor in tf.data.Dataset.from_tensor_slices(np_img_holder.astype(np.float32)).batch(1).take(sample_size):\n",
    "    yield [input_tensor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "aWksmw4Ai-d3",
    "outputId": "ce84e2fe-293c-4913-fb9b-e1c33d239e2a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content/tfrecord-dataset/flowers'"
      ]
     },
     "execution_count": 303,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-bo4dfILjCqF",
    "outputId": "7b0aa598-e341-40e2-9fab-de4e1beab217"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom_cnn\n",
      "dataset_info.json\n",
      "full_model\n",
      "image_classification_builder-test.tfrecord-00000-of-00001\n",
      "image_classification_builder-train.tfrecord-00000-of-00002\n",
      "image_classification_builder-train.tfrecord-00001-of-00002\n",
      "image_classification_builder-validation.tfrecord-00000-of-00001\n",
      "image-encoded.image.json\n",
      "quantized_resnet_vector\n"
     ]
    }
   ],
   "source": [
    "!ls /content/tfrecord-dataset/flowers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "CiAeQ0NLi7IS",
    "outputId": "3d086594-f873-40d9-f9c3-0bdfdedb8818"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\nroot_dir = root_dir\\nvalidation_pattern = \"{}/image_classification_builder-validation.tfrecord*\".format(root_dir)\\nvalidation_all_files = tf.data.Dataset.list_files( tf.io.gfile.glob(validation_pattern))\\n\\nvalidation_all_ds = tf.data.TFRecordDataset(validation_all_files, num_parallel_reads=tf.data.experimental.AUTOTUNE)\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "root_dir = root_dir\n",
    "validation_pattern = \"{}/image_classification_builder-validation.tfrecord*\".format(root_dir)\n",
    "validation_all_files = tf.data.Dataset.list_files( tf.io.gfile.glob(validation_pattern))\n",
    "\n",
    "validation_all_ds = tf.data.TFRecordDataset(validation_all_files, num_parallel_reads=tf.data.experimental.AUTOTUNE)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X_pKF2PvjMgF",
    "outputId": "ef7ea4d0-5729-4de2-afdb-3ef49d4e05bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size:  80\n"
     ]
    }
   ],
   "source": [
    "sample_size = 0\n",
    "for raw_record in val_all_ds:\n",
    "    sample_size += 1\n",
    "print('Sample size: ', sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "3l54Ptt3ltra",
    "outputId": "361122ab-9e4f-4b52-a08c-f351cba557b9"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content/tfrecord-dataset/flowers/full_model/full_resnet_vector_saved_model'"
      ]
     },
     "execution_count": 306,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jain-8Tph-to",
    "outputId": "46668a4d-2df3-4451-d343-958239d02a1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp5iox43wm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp5iox43wm/assets\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = data_generator\n",
    "# Ensure that if any ops can't be quantized, the converter throws an error\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "# Set the input and output tensors to uint8 (APIs added in r2.3)\n",
    "converter.inference_input_type = tf.uint8\n",
    "converter.inference_output_type = tf.uint8\n",
    "\n",
    "tflite_model_quant = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lM00I2oCUQv3"
   },
   "outputs": [],
   "source": [
    "## My local way load from savedModel directory\n",
    "'''\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_path)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = data_generator\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8, tf.lite.OpsSet.TFLITE_BUILTINS]\n",
    "converter.inference_input_type = tf.uint8  # or tf.uint8\n",
    "converter.inference_output_type = tf.uint8  # or tf.uint8\n",
    "tflite_model_quant = converter.convert()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "LCX0PAQGkHUQ",
    "outputId": "bddab6d4-9923-4b06-fd80-1eb852569f41"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content/tfrecord-dataset/flowers/full_model/full_resnet_vector_saved_model'"
      ]
     },
     "execution_count": 308,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D_cuefOqkJBE",
    "outputId": "ba56ce67-19c4-4872-ed7d-6892c68031d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 2385\n",
      "-rw-r--r-- 1 root root 2441500 Oct 31 22:30 saved_model.pb\n",
      "drwxr-xr-x 1 root root       0 Oct 31 22:31 assets\n",
      "drwxr-xr-x 1 root root       0 Oct 31 22:31 variables\n"
     ]
    }
   ],
   "source": [
    "!ls -lrt {saved_model_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xg6-Co4nVkLe"
   },
   "outputs": [],
   "source": [
    "#loaded_back_saved_model = tf.saved_model.load(saved_model_path)\n",
    "load_back_saved_model = tf.keras.models.load_model(saved_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RkjuSr3RWGsp",
    "outputId": "51b34144-08c7-4fc3-d634-d0174544785c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x7fd6219c0e48>"
      ]
     },
     "execution_count": 208,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_back_saved_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5Ps-DKbgV2QC",
    "outputId": "05199511-fa0e-4dd0-aaec-5aba657785ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp78tfefw7/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp78tfefw7/assets\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(loaded_back_saved_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = data_generator\n",
    "# Ensure that if any ops can't be quantized, the converter throws an error\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "# Set the input and output tensors to uint8 (APIs added in r2.3)\n",
    "#converter.inference_input_type = tf.uint8\n",
    "#converter.inference_output_type = tf.uint8\n",
    "\n",
    "tflite_model_quant = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ypIX2k5CiR2e",
    "outputId": "fcaf7eed-ed3a-4464-dabc-93691c1ef509"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  <class 'numpy.uint8'>\n",
      "output:  <class 'numpy.uint8'>\n"
     ]
    }
   ],
   "source": [
    "# This requires r2.3 API\n",
    "interpreter = tf.lite.Interpreter(model_content=tflite_model_quant)\n",
    "input_type = interpreter.get_input_details()[0]['dtype']\n",
    "print('input: ', input_type)\n",
    "output_type = interpreter.get_output_details()[0]['dtype']\n",
    "print('output: ', output_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cj6zlcdnp00i"
   },
   "source": [
    "## Saving quantized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "id": "x3158_GKkYrF"
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "root_dir = root_dir\n",
    "tflite_models_dir = 'quantized_resnet_vector/tflite_int8_model'\n",
    "\n",
    "to_save_tflite_model_dir = os.path.join(root_dir, tflite_models_dir)\n",
    "saved_tflite_models_dir = pathlib.Path(to_save_tflite_model_dir) #convert string to pathlib object\n",
    "saved_tflite_models_dir.mkdir(exist_ok=True, parents=True) # make directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2fjF9Uf7kd9E",
    "outputId": "4db00033-4112-4c97-ed0e-ca65fb0f54e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24719744"
      ]
     },
     "execution_count": 312,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a pathlib object to save quantized model with path and file name.\n",
    "tgt = pathlib.Path(to_save_tflite_model_dir, 'converted_model_reduced.tflite')\n",
    "# Write quantized model to the file.\n",
    "tgt.write_bytes(tflite_model_quant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r5iMP0OLafr5",
    "outputId": "465345f6-7118-4d78-a260-96e234bcf8e6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/content/tfrecord-dataset/flowers/quantized_resnet_vector/tflite_int8_model/converted_model_reduced.tflite')"
      ]
     },
     "execution_count": 313,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NE3NdGhXp5Pq"
   },
   "source": [
    "## Preparing test dataset from TFRecord"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7pQ_gO6prv6g"
   },
   "source": [
    "### Load test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "id": "W2PvVkqpmFal"
   },
   "outputs": [],
   "source": [
    "test_pattern = \"{}/image_classification_builder-test.tfrecord*\".format(root_dir)\n",
    "test_all_files = tf.data.Dataset.list_files( tf.io.gfile.glob(test_pattern))\n",
    "\n",
    "test_all_ds = tf.data.TFRecordDataset(test_all_files, num_parallel_reads=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qH648t_GqEPD",
    "outputId": "3fd3e7ce-7217-4acf-d6d2-8efe07681d67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size:  50\n"
     ]
    }
   ],
   "source": [
    "sample_size = 0\n",
    "for raw_record in test_all_ds:\n",
    "    sample_size += 1\n",
    "print('Sample size: ', sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "id": "f6iG5hpQqKEy"
   },
   "outputs": [],
   "source": [
    "decoded = test_all_ds.map(decode_and_resize)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mcPyDYkjqRxk"
   },
   "source": [
    "Convert `TFRecord` to numpy array for scoring:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "id": "MEdS25bpqNly"
   },
   "outputs": [],
   "source": [
    "np_img_holder = np.empty((0, 224, 224,3), float)\n",
    "np_lbl_holder = np.empty((0, 5), int)\n",
    "for img, lbl in decoded:\n",
    "    r = img.numpy() # image value extracted\n",
    "    rx = np.expand_dims(r, axis=0) # expand by adding a dimension for batching images.\n",
    "    lx = np.expand_dims(lbl, axis=0) # expand by adding a dimension for batching labels.\n",
    "    np_img_holder = np.append(np_img_holder, rx, axis=0) # append each image to create a batch of images.\n",
    "    np_lbl_holder = np.append(np_lbl_holder, lx, axis=0) # append each one-hot label to create a batch of labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CVBEvd1MzQ69",
    "outputId": "07fc1165-3e8e-4156-f18a-55bb0868f6cd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[208., 217., 160.],\n",
       "         [215., 227., 155.],\n",
       "         [216., 228., 144.],\n",
       "         ...,\n",
       "         [109., 150., 142.],\n",
       "         [115., 156., 148.],\n",
       "         [108., 149., 145.]],\n",
       "\n",
       "        [[216., 226., 165.],\n",
       "         [215., 225., 152.],\n",
       "         [224., 236., 152.],\n",
       "         ...,\n",
       "         [164., 201., 209.],\n",
       "         [169., 204., 210.],\n",
       "         [154., 189., 195.]],\n",
       "\n",
       "        [[210., 221., 155.],\n",
       "         [213., 224., 148.],\n",
       "         [220., 234., 149.],\n",
       "         ...,\n",
       "         [180., 213., 228.],\n",
       "         [174., 211., 220.],\n",
       "         [168., 205., 213.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 92., 153., 112.],\n",
       "         [ 68., 122.,  60.],\n",
       "         [ 65., 115.,  56.],\n",
       "         ...,\n",
       "         [ 73., 141., 120.],\n",
       "         [ 74., 144., 120.],\n",
       "         [ 76., 146., 122.]],\n",
       "\n",
       "        [[ 94., 156., 117.],\n",
       "         [ 87., 143.,  82.],\n",
       "         [ 55., 107.,  45.],\n",
       "         ...,\n",
       "         [ 82., 156., 141.],\n",
       "         [ 91., 161., 150.],\n",
       "         [ 87., 157., 147.]],\n",
       "\n",
       "        [[ 95., 159., 122.],\n",
       "         [106., 163., 110.],\n",
       "         [ 27.,  82.,  17.],\n",
       "         ...,\n",
       "         [ 91., 162., 164.],\n",
       "         [ 81., 151., 149.],\n",
       "         [ 80., 151., 147.]]],\n",
       "\n",
       "\n",
       "       [[[ 81.,  99.,  73.],\n",
       "         [ 79.,  97.,  71.],\n",
       "         [ 75.,  95.,  68.],\n",
       "         ...,\n",
       "         [ 50.,  75.,  36.],\n",
       "         [ 50.,  75.,  36.],\n",
       "         [ 49.,  74.,  35.]],\n",
       "\n",
       "        [[ 80.,  98.,  72.],\n",
       "         [ 77.,  97.,  70.],\n",
       "         [ 75.,  95.,  68.],\n",
       "         ...,\n",
       "         [ 49.,  74.,  35.],\n",
       "         [ 49.,  74.,  35.],\n",
       "         [ 49.,  74.,  35.]],\n",
       "\n",
       "        [[ 77.,  97.,  69.],\n",
       "         [ 76.,  96.,  68.],\n",
       "         [ 75.,  95.,  67.],\n",
       "         ...,\n",
       "         [ 47.,  72.,  33.],\n",
       "         [ 48.,  73.,  34.],\n",
       "         [ 48.,  73.,  34.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 71., 100.,  56.],\n",
       "         [ 72., 101.,  57.],\n",
       "         [ 74., 102.,  61.],\n",
       "         ...,\n",
       "         [ 71.,  98.,  63.],\n",
       "         [ 72.,  99.,  64.],\n",
       "         [ 70.,  98.,  60.]],\n",
       "\n",
       "        [[ 71., 100.,  56.],\n",
       "         [ 72., 101.,  57.],\n",
       "         [ 74., 102.,  61.],\n",
       "         ...,\n",
       "         [ 69.,  96.,  61.],\n",
       "         [ 69.,  96.,  61.],\n",
       "         [ 68.,  96.,  58.]],\n",
       "\n",
       "        [[ 71., 100.,  56.],\n",
       "         [ 72., 101.,  57.],\n",
       "         [ 72., 100.,  59.],\n",
       "         ...,\n",
       "         [ 64.,  91.,  56.],\n",
       "         [ 65.,  92.,  57.],\n",
       "         [ 63.,  91.,  53.]]],\n",
       "\n",
       "\n",
       "       [[[208.,  44.,  97.],\n",
       "         [202.,  40.,  90.],\n",
       "         [200.,  42.,  90.],\n",
       "         ...,\n",
       "         [ 69., 135., 123.],\n",
       "         [ 73., 144., 130.],\n",
       "         [ 78., 144., 132.]],\n",
       "\n",
       "        [[203.,  42.,  94.],\n",
       "         [200.,  42.,  91.],\n",
       "         [194.,  41.,  88.],\n",
       "         ...,\n",
       "         [ 71., 139., 128.],\n",
       "         [ 69., 140., 126.],\n",
       "         [ 68., 134., 122.]],\n",
       "\n",
       "        [[200.,  41.,  95.],\n",
       "         [199.,  42.,  93.],\n",
       "         [190.,  38.,  85.],\n",
       "         ...,\n",
       "         [ 68., 136., 125.],\n",
       "         [ 63., 133., 122.],\n",
       "         [ 63., 126., 115.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 61., 116.,  85.],\n",
       "         [ 61., 116.,  85.],\n",
       "         [ 51., 101.,  74.],\n",
       "         ...,\n",
       "         [ 91.,  27.,  41.],\n",
       "         [ 97.,  31.,  43.],\n",
       "         [ 99.,  31.,  44.]],\n",
       "\n",
       "        [[ 60., 113.,  83.],\n",
       "         [ 64., 119.,  88.],\n",
       "         [ 55., 105.,  78.],\n",
       "         ...,\n",
       "         [ 84.,  34.,  43.],\n",
       "         [ 88.,  26.,  39.],\n",
       "         [ 95.,  29.,  43.]],\n",
       "\n",
       "        [[ 48., 101.,  73.],\n",
       "         [ 62., 117.,  88.],\n",
       "         [ 66., 119.,  93.],\n",
       "         ...,\n",
       "         [ 71.,  66.,  62.],\n",
       "         [ 78.,  35.,  44.],\n",
       "         [ 90.,  36.,  49.]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[218., 202., 187.],\n",
       "         [193., 185., 172.],\n",
       "         [173., 170., 153.],\n",
       "         ...,\n",
       "         [204., 173., 126.],\n",
       "         [195., 166., 122.],\n",
       "         [195., 170., 130.]],\n",
       "\n",
       "        [[220., 204., 189.],\n",
       "         [194., 187., 171.],\n",
       "         [175., 169., 153.],\n",
       "         ...,\n",
       "         [202., 171., 124.],\n",
       "         [193., 164., 120.],\n",
       "         [191., 168., 127.]],\n",
       "\n",
       "        [[219., 203., 187.],\n",
       "         [192., 185., 169.],\n",
       "         [173., 167., 151.],\n",
       "         ...,\n",
       "         [201., 170., 123.],\n",
       "         [191., 164., 119.],\n",
       "         [188., 167., 124.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 50.,  49.,  31.],\n",
       "         [ 67.,  62.,  43.],\n",
       "         [ 69.,  66.,  49.],\n",
       "         ...,\n",
       "         [160., 146.,  99.],\n",
       "         [171., 154., 102.],\n",
       "         [187., 163., 115.]],\n",
       "\n",
       "        [[ 50.,  49.,  31.],\n",
       "         [ 67.,  62.,  43.],\n",
       "         [ 68.,  65.,  48.],\n",
       "         ...,\n",
       "         [155., 141.,  96.],\n",
       "         [169., 151., 101.],\n",
       "         [183., 159., 113.]],\n",
       "\n",
       "        [[ 50.,  49.,  31.],\n",
       "         [ 66.,  61.,  42.],\n",
       "         [ 67.,  64.,  47.],\n",
       "         ...,\n",
       "         [150., 133.,  89.],\n",
       "         [166., 148.,  98.],\n",
       "         [181., 157., 111.]]],\n",
       "\n",
       "\n",
       "       [[[137., 136., 116.],\n",
       "         [134., 132., 117.],\n",
       "         [130., 128., 116.],\n",
       "         ...,\n",
       "         [164., 169., 147.],\n",
       "         [166., 171., 149.],\n",
       "         [153., 161., 138.]],\n",
       "\n",
       "        [[135., 136., 118.],\n",
       "         [122., 123., 109.],\n",
       "         [116., 113., 104.],\n",
       "         ...,\n",
       "         [182., 187., 165.],\n",
       "         [137., 145., 122.],\n",
       "         [129., 139., 115.]],\n",
       "\n",
       "        [[130., 132., 119.],\n",
       "         [113., 115., 104.],\n",
       "         [105., 104.,  99.],\n",
       "         ...,\n",
       "         [145., 153., 132.],\n",
       "         [126., 135., 114.],\n",
       "         [126., 138., 116.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 29.,  10.,  40.],\n",
       "         [ 28.,   9.,  37.],\n",
       "         [ 26.,  10.,  37.],\n",
       "         ...,\n",
       "         [ 52.,  24.,  85.],\n",
       "         [ 52.,  24.,  85.],\n",
       "         [ 55.,  27.,  88.]],\n",
       "\n",
       "        [[ 28.,   9.,  39.],\n",
       "         [ 26.,   7.,  35.],\n",
       "         [ 24.,   8.,  35.],\n",
       "         ...,\n",
       "         [ 53.,  25.,  86.],\n",
       "         [ 52.,  24.,  85.],\n",
       "         [ 52.,  24.,  85.]],\n",
       "\n",
       "        [[ 25.,   9.,  36.],\n",
       "         [ 22.,   6.,  33.],\n",
       "         [ 23.,   7.,  34.],\n",
       "         ...,\n",
       "         [ 53.,  25.,  86.],\n",
       "         [ 50.,  22.,  83.],\n",
       "         [ 50.,  22.,  83.]]],\n",
       "\n",
       "\n",
       "       [[[120., 121., 115.],\n",
       "         [120., 121., 113.],\n",
       "         [117., 119., 108.],\n",
       "         ...,\n",
       "         [106.,  11.,   0.],\n",
       "         [ 97.,   8.,   0.],\n",
       "         [ 93.,   5.,   0.]],\n",
       "\n",
       "        [[124., 125., 117.],\n",
       "         [121., 122., 114.],\n",
       "         [120., 122., 111.],\n",
       "         ...,\n",
       "         [127.,  30.,  11.],\n",
       "         [120.,  27.,   9.],\n",
       "         [114.,  21.,   4.]],\n",
       "\n",
       "        [[125., 126., 118.],\n",
       "         [120., 121., 113.],\n",
       "         [120., 122., 111.],\n",
       "         ...,\n",
       "         [138.,  39.,  18.],\n",
       "         [133.,  36.,  17.],\n",
       "         [126.,  29.,  12.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[  1.,   6.,   0.],\n",
       "         [  2.,   7.,   0.],\n",
       "         [  0.,   5.,   0.],\n",
       "         ...,\n",
       "         [116.,  26.,   2.],\n",
       "         [109.,  22.,   2.],\n",
       "         [108.,  23.,   2.]],\n",
       "\n",
       "        [[  1.,   6.,   0.],\n",
       "         [  2.,   7.,   0.],\n",
       "         [  0.,   5.,   0.],\n",
       "         ...,\n",
       "         [115.,  25.,   1.],\n",
       "         [105.,  18.,   0.],\n",
       "         [105.,  20.,   0.]],\n",
       "\n",
       "        [[  1.,   6.,   0.],\n",
       "         [  0.,   5.,   0.],\n",
       "         [  0.,   5.,   0.],\n",
       "         ...,\n",
       "         [107.,  17.,   0.],\n",
       "         [108.,  20.,   0.],\n",
       "         [103.,  18.,   0.]]]], dtype=float32)"
      ]
     },
     "execution_count": 329,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_img_holder.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gde0f41oqmPr"
   },
   "source": [
    "Now test data is in numpy format with standardized dimension, pixel value between 0 and 255, and batched. So are labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PhtWkshWr1Wh"
   },
   "source": [
    "### Mapping prediction to class name\n",
    "From TFRecord, I need to create a reverse lookup dictionary to map probability back to label. In other words, I want to find the index where maximum probability is positioned in the array. Map this position index to flower type. To create the lookup dictionary, I need to parse the TFRecord with feature descriptions to extract label indices and names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "id": "-JDlxmv8r5I-"
   },
   "outputs": [],
   "source": [
    "feature_description = {\n",
    "    'image/channels' :  tf.io.FixedLenFeature([], tf.int64),\n",
    "    'image/class/label' :  tf.io.FixedLenFeature([], tf.int64),\n",
    "    'image/class/text' : tf.io.FixedLenFeature([], tf.string),\n",
    "    'image/colorspace' : tf.io.FixedLenFeature([], tf.string),\n",
    "    'image/encoded' : tf.io.FixedLenFeature([], tf.string),\n",
    "    'image/filename' : tf.io.FixedLenFeature([], tf.string),\n",
    "    'image/format' : tf.io.FixedLenFeature([], tf.string),\n",
    "    'image/height' : tf.io.FixedLenFeature([], tf.int64),\n",
    "    'image/width' : tf.io.FixedLenFeature([], tf.int64)\n",
    "}\n",
    "\n",
    "def _parse_function(example_proto):\n",
    "  return tf.io.parse_single_example(example_proto, feature_description)\n",
    "\n",
    "parsd_ds = test_all_ds.map(_parse_function)\n",
    "\n",
    "val_label_map = {}\n",
    "# getting label mapping\n",
    "for image_features in parsd_ds.take(30):\n",
    "    label_idx = image_features['image/class/label'].numpy()\n",
    "    label_str = image_features['image/class/text'].numpy().decode()\n",
    "    if label_idx not in val_label_map:\n",
    "        val_label_map[label_idx] = label_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nNYPhum7sDPR",
    "outputId": "142d24be-b09a-4027-cba6-037d6b88add0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'roses', 1: 'sunflowers', 2: 'daisy', 3: 'dandelion', 4: 'tulips'}"
      ]
     },
     "execution_count": 319,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "id": "sW_xt1I42zQ3"
   },
   "outputs": [],
   "source": [
    "actual = []\n",
    "for i in range(len(np_lbl_holder)):\n",
    "    class_key = np.argmax(np_lbl_holder[i])\n",
    "    actual.append(val_label_map.get(class_key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iz1uCxPUqvqm"
   },
   "source": [
    "### Scoring batch images with integer quantization model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "id": "5FIU2fhRqRJG"
   },
   "outputs": [],
   "source": [
    "def lookup(np_entry, dictionary):\n",
    "    class_key = np.argmax(np_entry)\n",
    "    return dictionary.get(class_key)\n",
    "    \n",
    "def batch_predict(input_raw, input_tensor, output_tensor, dictionary):\n",
    "    input_data = np.array(np.expand_dims(input_raw, axis=0), dtype=np.uint8)\n",
    "    interpreter.set_tensor(input_tensor['index'], input_data)\n",
    "    interpreter.invoke()\n",
    "    interpreter_output = interpreter.get_tensor(output_tensor['index'])\n",
    "    plain_text_label = lookup(interpreter_output, dictionary)\n",
    "    print(interpreter_output)\n",
    "    return plain_text_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rdaTdTdurat9"
   },
   "source": [
    "### Load quantized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OvYtmYqFselx",
    "outputId": "e5bb4de2-69fc-4c32-dbb4-965135ec817c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/content/tfrecord-dataset/flowers/quantized_resnet_vector/tflite_int8_model/converted_model_reduced.tflite')"
      ]
     },
     "execution_count": 322,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "id": "PFpHBivSrds3"
   },
   "outputs": [],
   "source": [
    "##Load the TFLite model and allocate tensors.\n",
    "## tgt is the pathlib object referring to file path and <TFLITE_MODEL_NAME>.tflite\n",
    "interpreter = tf.lite.Interpreter(model_path=str(tgt))\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "id": "77QLlmLVrf7e"
   },
   "outputs": [],
   "source": [
    "# Get input and output tensors.\n",
    "input_details = interpreter.get_input_details()[0]\n",
    "output_details = interpreter.get_output_details()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_DdEDG6ysHnl",
    "outputId": "c490d2b9-5c5a-4575-8a0c-4e559a15803f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dtype': numpy.uint8,\n",
       " 'index': 270,\n",
       " 'name': 'input_3',\n",
       " 'quantization': (0.0058823530562222, 0),\n",
       " 'quantization_parameters': {'quantized_dimension': 0,\n",
       "  'scales': array([0.00588235], dtype=float32),\n",
       "  'zero_points': array([0], dtype=int32)},\n",
       " 'shape': array([  1, 224, 224,   3], dtype=int32),\n",
       " 'shape_signature': array([ -1, 224, 224,   3], dtype=int32),\n",
       " 'sparsity_parameters': {}}"
      ]
     },
     "execution_count": 325,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5i1GuLsDtU1_",
    "outputId": "b21b73ca-120f-4aca-961d-12980b7227e0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dtype': numpy.uint8,\n",
       " 'index': 271,\n",
       " 'name': 'Identity',\n",
       " 'quantization': (0.00390625, 0),\n",
       " 'quantization_parameters': {'quantized_dimension': 0,\n",
       "  'scales': array([0.00390625], dtype=float32),\n",
       "  'zero_points': array([0], dtype=int32)},\n",
       " 'shape': array([1, 5], dtype=int32),\n",
       " 'shape_signature': array([-1,  5], dtype=int32),\n",
       " 'sparsity_parameters': {}}"
      ]
     },
     "execution_count": 326,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "id": "c66lY4VquWaa"
   },
   "outputs": [],
   "source": [
    "# Test the model\n",
    "input_data = np.array(np.expand_dims(np_img_holder[0], axis=0), dtype=np.uint8)\n",
    "interpreter.set_tensor(input_details['index'], input_data)\n",
    "interpreter.invoke()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vNgpMgXbrHyv",
    "outputId": "68e6d8b2-5e0b-4036-88d7-ac6429059181"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0 255]]\n",
      "0 tulips\n",
      "[[  1  34   1 220   0]]\n",
      "1 dandelion\n",
      "[[  0   0   0   0 255]]\n",
      "2 tulips\n"
     ]
    }
   ],
   "source": [
    "batch_quantized_prediction = []\n",
    "for i in range(sample_size - 47):\n",
    "    plain_text_label = batch_predict(np_img_holder[i], input_details, output_details, val_label_map)\n",
    "    batch_quantized_prediction.append(plain_text_label)\n",
    "    print(i, plain_text_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "53aK_Ll729Kv",
    "outputId": "9df50c44-be07-4dc4-e73d-ae3f8b2a212b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tulips',\n",
       " 'dandelion',\n",
       " 'tulips',\n",
       " 'sunflowers',\n",
       " 'daisy',\n",
       " 'sunflowers',\n",
       " 'daisy',\n",
       " 'roses',\n",
       " 'dandelion',\n",
       " 'tulips',\n",
       " 'dandelion',\n",
       " 'tulips',\n",
       " 'dandelion',\n",
       " 'tulips',\n",
       " 'roses',\n",
       " 'sunflowers',\n",
       " 'daisy',\n",
       " 'sunflowers',\n",
       " 'sunflowers',\n",
       " 'daisy',\n",
       " 'sunflowers',\n",
       " 'roses',\n",
       " 'dandelion',\n",
       " 'sunflowers',\n",
       " 'roses',\n",
       " 'tulips',\n",
       " 'tulips',\n",
       " 'tulips',\n",
       " 'sunflowers',\n",
       " 'roses',\n",
       " 'roses',\n",
       " 'daisy',\n",
       " 'sunflowers',\n",
       " 'sunflowers',\n",
       " 'tulips',\n",
       " 'dandelion',\n",
       " 'daisy',\n",
       " 'daisy',\n",
       " 'roses',\n",
       " 'sunflowers',\n",
       " 'roses',\n",
       " 'dandelion',\n",
       " 'daisy',\n",
       " 'tulips',\n",
       " 'sunflowers',\n",
       " 'daisy',\n",
       " 'daisy',\n",
       " 'roses',\n",
       " 'daisy',\n",
       " 'roses']"
      ]
     },
     "execution_count": 49,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_quantized_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o3jQeInUrJ3t",
    "outputId": "d1c033ea-2d74-4357-daa9-3a94b95a1a31"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82"
      ]
     },
     "execution_count": 50,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(actual, batch_quantized_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e76H1woL21U-"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "V2_50_4_Integer_Quantization_Colab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
