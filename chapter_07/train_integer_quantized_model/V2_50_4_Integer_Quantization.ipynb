{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aqtov3buhFgG",
    "outputId": "ed46a551-0dd9-4d88-f5ce-12cab0c199aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import os\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "kFT_pDYghbtK"
   },
   "outputs": [],
   "source": [
    "root_dir = '../train_base_model/tf_datasets/flower_photos'\n",
    "file_pattern = \"{}/image_classification_builder-train*.tfrecord*\".format(root_dir)\n",
    "val_file_pattern = \"{}/image_classification_builder-validation*.tfrecord*\".format(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "PVsmBp3dheis"
   },
   "outputs": [],
   "source": [
    "file_list = tf.io.gfile.glob(file_pattern)\n",
    "all_files = tf.data.Dataset.list_files( tf.io.gfile.glob(file_pattern))\n",
    "\n",
    "val_file_list = tf.io.gfile.glob(val_file_pattern)\n",
    "val_all_files = tf.data.Dataset.list_files( tf.io.gfile.glob(val_file_pattern))\n",
    "\n",
    "train_all_ds = tf.data.TFRecordDataset(all_files, num_parallel_reads=tf.data.experimental.AUTOTUNE)\n",
    "val_all_ds = tf.data.TFRecordDataset(val_all_files, num_parallel_reads=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "lmLfUUcChgyj"
   },
   "outputs": [],
   "source": [
    "def decode_and_resize(serialized_example):\n",
    "    # resized image should be [224, 224, 3] and normalized to value range [0, 255] \n",
    "    # label is integer index of class.\n",
    "    \n",
    "    parsed_features = tf.io.parse_single_example(\n",
    "    serialized_example,\n",
    "    features = {\n",
    "    'image/channels' :  tf.io.FixedLenFeature([], tf.int64),\n",
    "    'image/class/label' :  tf.io.FixedLenFeature([], tf.int64),\n",
    "    'image/class/text' : tf.io.FixedLenFeature([], tf.string),\n",
    "    'image/colorspace' : tf.io.FixedLenFeature([], tf.string),\n",
    "    'image/encoded' : tf.io.FixedLenFeature([], tf.string),\n",
    "    'image/filename' : tf.io.FixedLenFeature([], tf.string),\n",
    "    'image/format' : tf.io.FixedLenFeature([], tf.string),\n",
    "    'image/height' : tf.io.FixedLenFeature([], tf.int64),\n",
    "    'image/width' : tf.io.FixedLenFeature([], tf.int64)\n",
    "    })\n",
    "    image = tf.io.decode_jpeg(parsed_features['image/encoded'], channels=3)\n",
    "    label = tf.cast(parsed_features['image/class/label'], tf.int32)\n",
    "    label_txt = tf.cast(parsed_features['image/class/text'], tf.string)\n",
    "    label_one_hot = tf.one_hot(label, depth = 5)\n",
    "    resized_image = tf.image.resize(image, [224, 224], method='nearest')\n",
    "    return resized_image, label_one_hot\n",
    "\n",
    "def normalize(image, label):\n",
    "    #Convert `image` from [0, 255] -> [0, 1.0] floats \n",
    "    image = tf.cast(image, tf.float32) / 255. + 0.5\n",
    "    return image, label\n",
    "\n",
    "def prepare_for_training(ds, cache=True, shuffle_buffer_size=1000):\n",
    "    # This is a small dataset, only load it once, and keep it in memory.\n",
    "    # use `.cache(filename)` to cache preprocessing work for datasets that don't\n",
    "    # fit in memory.\n",
    "\n",
    "    if cache:\n",
    "        if isinstance(cache, str):\n",
    "            ds = ds.cache(cache)\n",
    "        else:\n",
    "            ds = ds.cache()\n",
    "\n",
    "    ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
    "    # Repeat forever\n",
    "    ds = ds.repeat()\n",
    "    ds = ds.batch(32)\n",
    "    # `prefetch` lets the dataset fetch batches in the background while the model\n",
    "    # is training.\n",
    "    AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "    ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Oc8CKnNXhnQ9"
   },
   "outputs": [],
   "source": [
    "# perform data engineering \n",
    "dataset = train_all_ds.map(decode_and_resize)\n",
    "val_dataset = val_all_ds.map(decode_and_resize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "CUSbDz4xhpy-"
   },
   "outputs": [],
   "source": [
    "# Create dataset for training run\n",
    "BATCH_SIZE = 32\n",
    "VALIDATION_BATCH_SIZE = 40\n",
    "dataset = dataset.map(normalize, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "val_dataset = val_dataset.map(normalize, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "val_ds = val_dataset.batch(VALIDATION_BATCH_SIZE)\n",
    "    \n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "train_ds = prepare_for_training(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GNCkQOXFhrM5",
    "outputId": "3f276f22-9b1a-4ac5-98c2-2cc6481e1c30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_SAMPLE_SIZE =  3540\n",
      "VALIDATION_SAMPLE_SIZE =  80\n"
     ]
    }
   ],
   "source": [
    "NUM_CLASSES = 5\n",
    "IMAGE_SIZE = (224, 224)\n",
    "    \n",
    "train_sample_size=0\n",
    "for raw_record in train_all_ds:\n",
    "    train_sample_size += 1\n",
    "print('TRAIN_SAMPLE_SIZE = ', train_sample_size)\n",
    "validation_sample_size=0\n",
    "for raw_record in val_all_ds:\n",
    "    validation_sample_size += 1\n",
    "print('VALIDATION_SAMPLE_SIZE = ', validation_sample_size)\n",
    "\n",
    "STEPS_PER_EPOCHS = train_sample_size // BATCH_SIZE\n",
    "VALIDATION_STEPS = validation_sample_size // VALIDATION_BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "SdYqNE-Hht_d"
   },
   "outputs": [],
   "source": [
    "os.environ[\"TFHUB_CACHE_DIR\"] = '../imagenet_resnet_v2_50_feature_vector_4'\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape=IMAGE_SIZE + (3,)),\n",
    "    hub.KerasLayer(\"https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/4\",\n",
    "                   trainable=False),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(units = 64, activation = 'relu', kernel_initializer='glorot_uniform'),\n",
    "    tf.keras.layers.Dense(NUM_CLASSES, activation='softmax', name = 'custom_class')\n",
    "])\n",
    "\n",
    "model.build([None, 224, 224, 3])\n",
    "\n",
    "model.compile(\n",
    "  optimizer=tf.keras.optimizers.SGD(lr=0.005, momentum=0.9), \n",
    "  loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True, label_smoothing=0.1),\n",
    "  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jo2JOl1ehweQ",
    "outputId": "9fbb14cc-145b-43e2-d3cb-d4fe1b57f0ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "keras_layer (KerasLayer)     (None, 2048)              23564800  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                131136    \n",
      "_________________________________________________________________\n",
      "custom_class (Dense)         (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 23,696,261\n",
      "Trainable params: 131,461\n",
      "Non-trainable params: 23,564,800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "herMqp_KhzEA"
   },
   "outputs": [],
   "source": [
    "decoded = val_all_ds.map(decode_and_resize)\n",
    "normed = decoded.map(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "bWxr3qyGiiND"
   },
   "outputs": [],
   "source": [
    "np_img_holder = np.empty((0, 224, 224,3), float)\n",
    "np_lbl_holder = np.empty((0, 5), int)\n",
    "for img, lbl in normed:\n",
    "    r = img.numpy() # image value extracted\n",
    "    rx = np.expand_dims(r, axis=0) # expand by adding a dimension for batching images.\n",
    "    lx = np.expand_dims(lbl, axis=0) # expand by adding a dimension for batching labels.\n",
    "    np_img_holder = np.append(np_img_holder, rx, axis=0) # append each image to create a batch of images.\n",
    "    np_lbl_holder = np.append(np_lbl_holder, lx, axis=0) # append each one-hot label to create a batch of labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GdSle3bbzvHi",
    "outputId": "0733690d-f9dc-45d0-ac09-2d56ab0ca8cd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[1.3039216 , 0.5352941 , 0.6215686 ],\n",
       "         [1.2921569 , 0.5117647 , 0.6333333 ],\n",
       "         [1.3352941 , 0.5470588 , 0.68039215],\n",
       "         ...,\n",
       "         [1.1117647 , 0.982353  , 1.009804  ],\n",
       "         [1.0058824 , 0.8843137 , 0.9078431 ],\n",
       "         [0.71960783, 0.55490196, 0.59411764]],\n",
       "\n",
       "        [[1.2686274 , 0.5117647 , 0.57843137],\n",
       "         [1.2568628 , 0.5       , 0.60588235],\n",
       "         [1.3039216 , 0.53137255, 0.6490196 ],\n",
       "         ...,\n",
       "         [1.0647058 , 0.93529415, 0.9627451 ],\n",
       "         [1.0607843 , 0.93921566, 0.9627451 ],\n",
       "         [0.82941175, 0.6843137 , 0.71568626]],\n",
       "\n",
       "        [[1.2411765 , 0.5156863 , 0.5470588 ],\n",
       "         [1.2176471 , 0.50784314, 0.5745098 ],\n",
       "         [1.2568628 , 0.527451  , 0.6098039 ],\n",
       "         ...,\n",
       "         [1.0254903 , 0.9       , 0.9196079 ],\n",
       "         [0.95490193, 0.8333334 , 0.8568628 ],\n",
       "         [0.88823533, 0.76666665, 0.7980392 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.5862745 , 0.64117646, 0.5392157 ],\n",
       "         [0.7705883 , 0.6607843 , 0.64509803],\n",
       "         [1.0137255 , 0.7784314 , 0.82549024],\n",
       "         ...,\n",
       "         [1.017647  , 0.5862745 , 0.5901961 ],\n",
       "         [1.0019608 , 0.6098039 , 0.6098039 ],\n",
       "         [0.9       , 0.6333333 , 0.62941176]],\n",
       "\n",
       "        [[0.5509804 , 0.5862745 , 0.5       ],\n",
       "         [0.8137255 , 0.66862744, 0.7       ],\n",
       "         [1.0333333 , 0.7588235 , 0.8607843 ],\n",
       "         ...,\n",
       "         [1.0019608 , 0.5470588 , 0.5588235 ],\n",
       "         [0.9470588 , 0.53137255, 0.5470588 ],\n",
       "         [0.87254906, 0.53137255, 0.56666666]],\n",
       "\n",
       "        [[0.56666666, 0.5901961 , 0.5       ],\n",
       "         [0.8411765 , 0.68039215, 0.74313724],\n",
       "         [1.017647  , 0.7235294 , 0.845098  ],\n",
       "         ...,\n",
       "         [1.0215687 , 0.5470588 , 0.56666666],\n",
       "         [0.9509804 , 0.5156863 , 0.5392157 ],\n",
       "         [0.8686274 , 0.5       , 0.5470588 ]]],\n",
       "\n",
       "\n",
       "       [[[1.4843137 , 1.5       , 1.4803922 ],\n",
       "         [1.4843137 , 1.5       , 1.4803922 ],\n",
       "         [1.4843137 , 1.5       , 1.4803922 ],\n",
       "         ...,\n",
       "         [1.4686275 , 1.154902  , 1.1980393 ],\n",
       "         [1.4607843 , 1.1588235 , 1.182353  ],\n",
       "         [1.4568627 , 1.182353  , 1.182353  ]],\n",
       "\n",
       "        [[1.4843137 , 1.5       , 1.4803922 ],\n",
       "         [1.4843137 , 1.5       , 1.4803922 ],\n",
       "         [1.4843137 , 1.5       , 1.4803922 ],\n",
       "         ...,\n",
       "         [1.4607843 , 1.1588235 , 1.1980393 ],\n",
       "         [1.464706  , 1.1705883 , 1.1980393 ],\n",
       "         [1.4372549 , 1.1666667 , 1.1784314 ]],\n",
       "\n",
       "        [[1.4921569 , 1.5       , 1.4882352 ],\n",
       "         [1.4921569 , 1.5       , 1.4882352 ],\n",
       "         [1.4882352 , 1.4960785 , 1.4843137 ],\n",
       "         ...,\n",
       "         [1.445098  , 1.1470588 , 1.1862745 ],\n",
       "         [1.4411764 , 1.154902  , 1.190196  ],\n",
       "         [1.472549  , 1.2137256 , 1.2529411 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1.3666667 , 1.1235294 , 1.3078432 ],\n",
       "         [1.3745098 , 1.1392157 , 1.3392158 ],\n",
       "         [1.3705883 , 1.1431372 , 1.3392158 ],\n",
       "         ...,\n",
       "         [1.1470588 , 0.78627455, 0.80588233],\n",
       "         [1.1627451 , 0.8019608 , 0.8215686 ],\n",
       "         [1.1627451 , 0.8019608 , 0.8137255 ]],\n",
       "\n",
       "        [[1.362745  , 1.1156863 , 1.2921569 ],\n",
       "         [1.3784313 , 1.1352942 , 1.327451  ],\n",
       "         [1.3745098 , 1.1431372 , 1.3313725 ],\n",
       "         ...,\n",
       "         [1.1862745 , 0.8215686 , 0.8647059 ],\n",
       "         [1.1784314 , 0.8137255 , 0.85294116],\n",
       "         [1.154902  , 0.7941177 , 0.8137255 ]],\n",
       "\n",
       "        [[1.3745098 , 1.127451  , 1.2960784 ],\n",
       "         [1.3745098 , 1.1313726 , 1.3156862 ],\n",
       "         [1.3784313 , 1.1352942 , 1.327451  ],\n",
       "         ...,\n",
       "         [1.2137256 , 0.845098  , 0.9078431 ],\n",
       "         [1.1862745 , 0.8215686 , 0.8647059 ],\n",
       "         [1.1627451 , 0.7980392 , 0.82941175]]],\n",
       "\n",
       "\n",
       "       [[[0.7       , 0.82549024, 0.76666665],\n",
       "         [0.6882353 , 0.80980396, 0.7470588 ],\n",
       "         [0.68039215, 0.8019608 , 0.7392157 ],\n",
       "         ...,\n",
       "         [0.71568626, 0.80588233, 0.5       ],\n",
       "         [0.69215685, 0.7980392 , 0.5       ],\n",
       "         [0.7078431 , 0.8333334 , 0.5352941 ]],\n",
       "\n",
       "        [[0.68039215, 0.8019608 , 0.74313724],\n",
       "         [0.64509803, 0.76666665, 0.70392156],\n",
       "         [0.64117646, 0.7509804 , 0.69215685],\n",
       "         ...,\n",
       "         [0.7509804 , 0.8411765 , 0.527451  ],\n",
       "         [0.7470588 , 0.8411765 , 0.5352941 ],\n",
       "         [0.7117647 , 0.8333334 , 0.51960784]],\n",
       "\n",
       "        [[0.64117646, 0.7509804 , 0.69215685],\n",
       "         [0.6098039 , 0.71960783, 0.6647059 ],\n",
       "         [0.60588235, 0.7078431 , 0.65686274],\n",
       "         ...,\n",
       "         [0.7745098 , 0.8607843 , 0.5352941 ],\n",
       "         [0.7823529 , 0.87254906, 0.5509804 ],\n",
       "         [0.73137254, 0.84901965, 0.5117647 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.5509804 , 0.5745098 , 0.5352941 ],\n",
       "         [0.5392157 , 0.56666666, 0.5352941 ],\n",
       "         [0.5235294 , 0.5509804 , 0.5235294 ],\n",
       "         ...,\n",
       "         [0.7588235 , 0.8411765 , 0.71960783],\n",
       "         [0.754902  , 0.845098  , 0.74313724],\n",
       "         [0.65294117, 0.74313724, 0.68039215]],\n",
       "\n",
       "        [[0.5392157 , 0.5627451 , 0.5156863 ],\n",
       "         [0.54313725, 0.5627451 , 0.5352941 ],\n",
       "         [0.5352941 , 0.55490196, 0.53137255],\n",
       "         ...,\n",
       "         [0.7078431 , 0.79019606, 0.6607843 ],\n",
       "         [0.70392156, 0.7980392 , 0.6960784 ],\n",
       "         [0.6490196 , 0.76274514, 0.6843137 ]],\n",
       "\n",
       "        [[0.53137255, 0.55490196, 0.5       ],\n",
       "         [0.5509804 , 0.5745098 , 0.5352941 ],\n",
       "         [0.54313725, 0.5627451 , 0.5392157 ],\n",
       "         ...,\n",
       "         [0.64117646, 0.7235294 , 0.59411764],\n",
       "         [0.64117646, 0.7392157 , 0.6254902 ],\n",
       "         [0.6333333 , 0.7588235 , 0.66862744]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[1.0137255 , 1.182353  , 1.4882352 ],\n",
       "         [1.0137255 , 1.182353  , 1.4882352 ],\n",
       "         [1.0137255 , 1.182353  , 1.4882352 ],\n",
       "         ...,\n",
       "         [0.97843134, 1.1431372 , 1.4411764 ],\n",
       "         [0.97843134, 1.1431372 , 1.4411764 ],\n",
       "         [0.97450984, 1.1392157 , 1.4372549 ]],\n",
       "\n",
       "        [[1.017647  , 1.1862745 , 1.4921569 ],\n",
       "         [1.017647  , 1.1862745 , 1.4921569 ],\n",
       "         [1.017647  , 1.1862745 , 1.4921569 ],\n",
       "         ...,\n",
       "         [0.97843134, 1.1431372 , 1.4411764 ],\n",
       "         [0.97843134, 1.1431372 , 1.4411764 ],\n",
       "         [0.97450984, 1.1392157 , 1.4372549 ]],\n",
       "\n",
       "        [[1.017647  , 1.190196  , 1.4843137 ],\n",
       "         [1.017647  , 1.190196  , 1.4843137 ],\n",
       "         [1.017647  , 1.190196  , 1.4843137 ],\n",
       "         ...,\n",
       "         [0.97843134, 1.1392157 , 1.4490197 ],\n",
       "         [0.97843134, 1.1392157 , 1.4490197 ],\n",
       "         [0.97843134, 1.1392157 , 1.4490197 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1.1470588 , 1.2215686 , 0.76666665],\n",
       "         [1.1196079 , 1.2019608 , 0.70392156],\n",
       "         [1.1196079 , 1.2019608 , 0.70392156],\n",
       "         ...,\n",
       "         [1.0529412 , 1.1392157 , 0.99803925],\n",
       "         [1.0529412 , 1.1392157 , 0.99803925],\n",
       "         [0.91568625, 1.0215687 , 0.9470588 ]],\n",
       "\n",
       "        [[1.1039217 , 1.1862745 , 0.64117646],\n",
       "         [1.1       , 1.1862745 , 0.61764705],\n",
       "         [1.1       , 1.1862745 , 0.61764705],\n",
       "         ...,\n",
       "         [0.88823533, 0.97843134, 0.9078431 ],\n",
       "         [0.88823533, 0.97843134, 0.9078431 ],\n",
       "         [0.8372549 , 0.9470588 , 0.9627451 ]],\n",
       "\n",
       "        [[1.1509805 , 1.2411765 , 0.64509803],\n",
       "         [1.1235294 , 1.2137256 , 0.6137255 ],\n",
       "         [1.1235294 , 1.2137256 , 0.6137255 ],\n",
       "         ...,\n",
       "         [0.7784314 , 0.8686274 , 0.82941175],\n",
       "         [0.7784314 , 0.8686274 , 0.82941175],\n",
       "         [0.8686274 , 0.982353  , 1.0450981 ]]],\n",
       "\n",
       "\n",
       "       [[[1.3509804 , 1.4098039 , 1.0764706 ],\n",
       "         [1.2529411 , 1.327451  , 1.2098039 ],\n",
       "         [1.2529411 , 1.3392158 , 1.2882353 ],\n",
       "         ...,\n",
       "         [1.2411765 , 1.354902  , 1.2843137 ],\n",
       "         [1.2450981 , 1.3509804 , 1.2137256 ],\n",
       "         [1.3196079 , 1.4176471 , 1.0607843 ]],\n",
       "\n",
       "        [[1.2294118 , 1.2960784 , 1.0294118 ],\n",
       "         [0.845098  , 0.9235294 , 0.87647057],\n",
       "         [0.8333334 , 0.927451  , 0.9431373 ],\n",
       "         ...,\n",
       "         [0.78627455, 0.9039216 , 0.9039216 ],\n",
       "         [0.8607843 , 0.9666667 , 0.9       ],\n",
       "         [1.2137256 , 1.3039216 , 1.0215687 ]],\n",
       "\n",
       "        [[1.2686274 , 1.3509804 , 1.2215686 ],\n",
       "         [0.9666667 , 1.0647058 , 1.1509805 ],\n",
       "         [0.927451  , 1.0372549 , 1.190196  ],\n",
       "         ...,\n",
       "         [0.927451  , 1.0450981 , 1.1941177 ],\n",
       "         [0.93529415, 1.0411766 , 1.1235294 ],\n",
       "         [1.2294118 , 1.3235295 , 1.190196  ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1.2529411 , 1.3980392 , 1.2647059 ],\n",
       "         [1.0411766 , 1.1627451 , 1.3470588 ],\n",
       "         [1.017647  , 1.1313726 , 1.4294118 ],\n",
       "         ...,\n",
       "         [0.9941176 , 1.0803921 , 1.0294118 ],\n",
       "         [1.1156863 , 1.2058823 , 1.1745098 ],\n",
       "         [1.2803922 , 1.3745098 , 1.272549  ]],\n",
       "\n",
       "        [[1.1941177 , 1.3078432 , 1.0803921 ],\n",
       "         [1.0450981 , 1.1392157 , 1.1392157 ],\n",
       "         [1.0294118 , 1.1196079 , 1.190196  ],\n",
       "         ...,\n",
       "         [0.95490193, 1.0254903 , 0.7980392 ],\n",
       "         [1.2176471 , 1.2960784 , 1.0960784 ],\n",
       "         [1.2333333 , 1.3196079 , 1.0686275 ]],\n",
       "\n",
       "        [[1.4098039 , 1.4372549 , 1.0294118 ],\n",
       "         [1.327451  , 1.3588235 , 0.9627451 ],\n",
       "         [1.327451  , 1.3705883 , 0.9705882 ],\n",
       "         ...,\n",
       "         [1.2215686 , 1.2647059 , 0.76274514],\n",
       "         [1.3156862 , 1.3745098 , 0.8843137 ],\n",
       "         [1.362745  , 1.4254901 , 0.9078431 ]]],\n",
       "\n",
       "\n",
       "       [[[0.9196079 , 0.9235294 , 0.8607843 ],\n",
       "         [0.9078431 , 0.91176474, 0.8568628 ],\n",
       "         [0.9313725 , 0.9313725 , 0.8843137 ],\n",
       "         ...,\n",
       "         [0.8568628 , 0.8568628 , 0.8176471 ],\n",
       "         [0.8568628 , 0.8607843 , 0.8372549 ],\n",
       "         [0.82941175, 0.8411765 , 0.8137255 ]],\n",
       "\n",
       "        [[0.89215684, 0.89607847, 0.8333334 ],\n",
       "         [0.91568625, 0.9196079 , 0.8647059 ],\n",
       "         [0.91176474, 0.91176474, 0.8647059 ],\n",
       "         ...,\n",
       "         [0.85294116, 0.85294116, 0.8215686 ],\n",
       "         [0.845098  , 0.84901965, 0.8176471 ],\n",
       "         [0.845098  , 0.85294116, 0.80980396]],\n",
       "\n",
       "        [[0.91176474, 0.91568625, 0.8607843 ],\n",
       "         [0.91176474, 0.91176474, 0.8647059 ],\n",
       "         [0.927451  , 0.927451  , 0.8803922 ],\n",
       "         ...,\n",
       "         [0.8568628 , 0.85294116, 0.8372549 ],\n",
       "         [0.85294116, 0.84901965, 0.82941175],\n",
       "         [0.8568628 , 0.85294116, 0.8333334 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1.0254903 , 1.0294118 , 0.97450984],\n",
       "         [1.0019608 , 1.009804  , 0.9666667 ],\n",
       "         [0.97843134, 0.9901961 , 0.9627451 ],\n",
       "         ...,\n",
       "         [0.8137255 , 0.8137255 , 0.76666665],\n",
       "         [0.8019608 , 0.8019608 , 0.76274514],\n",
       "         [0.80588233, 0.8137255 , 0.7705883 ]],\n",
       "\n",
       "        [[1.0607843 , 1.0529412 , 1.0019608 ],\n",
       "         [1.0215687 , 1.0215687 , 0.982353  ],\n",
       "         [0.99803925, 1.009804  , 0.982353  ],\n",
       "         ...,\n",
       "         [0.84901965, 0.84901965, 0.8019608 ],\n",
       "         [0.845098  , 0.845098  , 0.80588233],\n",
       "         [0.84901965, 0.85294116, 0.8215686 ]],\n",
       "\n",
       "        [[1.0921569 , 1.0843138 , 1.0333333 ],\n",
       "         [1.0411766 , 1.0411766 , 1.0019608 ],\n",
       "         [1.017647  , 1.0294118 , 0.9941176 ],\n",
       "         ...,\n",
       "         [0.87254906, 0.87254906, 0.8333334 ],\n",
       "         [0.87647057, 0.87647057, 0.845098  ],\n",
       "         [0.8647059 , 0.87647057, 0.84901965]]]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_img_holder.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Bd4-CrMAh3BD"
   },
   "outputs": [],
   "source": [
    "checkpoint_prefix = os.path.join('trained_resnet_vector', \"train_ckpt_{epoch}\")\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.TensorBoard(log_dir=os.path.join('trained_resnet_vector', 'tensorboard_logs')),\n",
    "    tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wWfusFRbh8c5",
    "outputId": "b3bc5db6-46c1-482a-a4bf-3aa6f1d6a829"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "  1/110 [..............................] - ETA: 0s - loss: 1.6449 - accuracy: 0.1875WARNING:tensorflow:From /Users/mbp16/Documents/projects/tf23/lib/python3.8/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/mbp16/Documents/projects/tf23/lib/python3.8/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 92s 832ms/step - loss: 1.2953 - accuracy: 0.6639 - val_loss: 1.1900 - val_accuracy: 0.7875\n",
      "Epoch 2/5\n",
      "110/110 [==============================] - 93s 846ms/step - loss: 1.1406 - accuracy: 0.8449 - val_loss: 1.1456 - val_accuracy: 0.8500\n",
      "Epoch 3/5\n",
      "110/110 [==============================] - 93s 841ms/step - loss: 1.1124 - accuracy: 0.8722 - val_loss: 1.1243 - val_accuracy: 0.8625\n",
      "Epoch 4/5\n",
      "110/110 [==============================] - 90s 818ms/step - loss: 1.0947 - accuracy: 0.8932 - val_loss: 1.1282 - val_accuracy: 0.8500\n",
      "Epoch 5/5\n",
      "110/110 [==============================] - 94s 859ms/step - loss: 1.0840 - accuracy: 0.9026 - val_loss: 1.1252 - val_accuracy: 0.8375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa6435f0f10>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "        train_ds,\n",
    "        epochs=5, \n",
    "        steps_per_epoch=STEPS_PER_EPOCHS,\n",
    "        validation_data=val_ds,\n",
    "        validation_steps=VALIDATION_STEPS,\n",
    "        callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a trained model. It is not yet quantized. The integer quantization process actually requires some representative data as a reference, so possible ranges and distribution of values can be properly mapped from floating point to integer domain.\n",
    "It can be any data (training, validation, or test), and the recommended size is around 100. We can use our validation data, which contains 80 samples, and it will work just as well. \n",
    "Per TFLite's representative_dataset API, we need to specify a function that is a generator to stream the representative data during the conversion process. This function is `data_generator` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "VG9ViyIIiZop"
   },
   "outputs": [],
   "source": [
    "\n",
    "def data_generator():\n",
    "  for input_tensor in tf.data.Dataset.from_tensor_slices(np_img_holder.astype(np.float32)).batch(1).take(sample_size):\n",
    "    yield [input_tensor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X_pKF2PvjMgF",
    "outputId": "ef7ea4d0-5729-4de2-afdb-3ef49d4e05bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size:  80\n"
     ]
    }
   ],
   "source": [
    "sample_size = 0\n",
    "for raw_record in val_all_ds:\n",
    "    sample_size += 1\n",
    "print('Sample size: ', sample_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to start the conversion process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jain-8Tph-to",
    "outputId": "46668a4d-2df3-4451-d343-958239d02a1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/br/nbdf88sj3cj87dvsmzhkny0h0000gn/T/tmpd_2eyi5u/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/br/nbdf88sj3cj87dvsmzhkny0h0000gn/T/tmpd_2eyi5u/assets\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = data_generator\n",
    "# Ensure that if any ops can't be quantized, the converter throws an error\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "# Set the input and output tensors to uint8 (APIs added in r2.3)\n",
    "converter.inference_input_type = tf.uint8\n",
    "converter.inference_output_type = tf.uint8\n",
    "\n",
    "tflite_model_quant = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5Ps-DKbgV2QC",
    "outputId": "05199511-fa0e-4dd0-aaec-5aba657785ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp78tfefw7/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp78tfefw7/assets\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(loaded_back_saved_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = data_generator\n",
    "# Ensure that if any ops can't be quantized, the converter throws an error\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "# Set the input and output tensors to uint8 (APIs added in r2.3)\n",
    "#converter.inference_input_type = tf.uint8\n",
    "#converter.inference_output_type = tf.uint8\n",
    "\n",
    "tflite_model_quant = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ypIX2k5CiR2e",
    "outputId": "fcaf7eed-ed3a-4464-dabc-93691c1ef509"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  <class 'numpy.uint8'>\n",
      "output:  <class 'numpy.uint8'>\n"
     ]
    }
   ],
   "source": [
    "# This requires r2.3 API\n",
    "interpreter = tf.lite.Interpreter(model_content=tflite_model_quant)\n",
    "input_type = interpreter.get_input_details()[0]['dtype']\n",
    "print('input: ', input_type)\n",
    "output_type = interpreter.get_output_details()[0]['dtype']\n",
    "print('output: ', output_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cj6zlcdnp00i"
   },
   "source": [
    "## Saving quantized model\n",
    "Once the conversion process is complete, we may save the quantized model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "x3158_GKkYrF"
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "root_dir = root_dir\n",
    "tflite_models_dir = 'quantized_resnet_vector/tflite_int8_model'\n",
    "\n",
    "to_save_tflite_model_dir = os.path.join(root_dir, tflite_models_dir)\n",
    "saved_tflite_models_dir = pathlib.Path(to_save_tflite_model_dir) #convert string to pathlib object\n",
    "saved_tflite_models_dir.mkdir(exist_ok=True, parents=True) # make directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2fjF9Uf7kd9E",
    "outputId": "4db00033-4112-4c97-ed0e-ca65fb0f54e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24717552"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a pathlib object 'tgt' to save quantized model with path and file name.\n",
    "tgt = pathlib.Path(to_save_tflite_model_dir, 'converted_model_reduced.tflite')\n",
    "# Write quantized model to the file.\n",
    "tgt.write_bytes(tflite_model_quant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The quantized model's size is 24 MB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r5iMP0OLafr5",
    "outputId": "465345f6-7118-4d78-a260-96e234bcf8e6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('../train_base_model/tf_datasets/flower_photos/quantized_resnet_vector/tflite_int8_model/converted_model_reduced.tflite')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NE3NdGhXp5Pq"
   },
   "source": [
    "## Preparing test dataset from TFRecord"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7pQ_gO6prv6g"
   },
   "source": [
    "### Load test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "W2PvVkqpmFal"
   },
   "outputs": [],
   "source": [
    "test_pattern = \"{}/image_classification_builder-test.tfrecord*\".format(root_dir)\n",
    "test_all_files = tf.data.Dataset.list_files( tf.io.gfile.glob(test_pattern))\n",
    "\n",
    "test_all_ds = tf.data.TFRecordDataset(test_all_files, num_parallel_reads=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qH648t_GqEPD",
    "outputId": "3fd3e7ce-7217-4acf-d6d2-8efe07681d67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size:  50\n"
     ]
    }
   ],
   "source": [
    "sample_size = 0\n",
    "for raw_record in test_all_ds:\n",
    "    sample_size += 1\n",
    "print('Sample size: ', sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "f6iG5hpQqKEy"
   },
   "outputs": [],
   "source": [
    "decoded = test_all_ds.map(decode_and_resize)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mcPyDYkjqRxk"
   },
   "source": [
    "Convert `TFRecord` to numpy array for scoring:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "MEdS25bpqNly"
   },
   "outputs": [],
   "source": [
    "np_img_holder = np.empty((0, 224, 224,3), float)\n",
    "np_lbl_holder = np.empty((0, 5), int)\n",
    "for img, lbl in decoded:\n",
    "    r = img.numpy() # image value extracted\n",
    "    rx = np.expand_dims(r, axis=0) # expand by adding a dimension for batching images.\n",
    "    lx = np.expand_dims(lbl, axis=0) # expand by adding a dimension for batching labels.\n",
    "    np_img_holder = np.append(np_img_holder, rx, axis=0) # append each image to create a batch of images.\n",
    "    np_lbl_holder = np.append(np_lbl_holder, lx, axis=0) # append each one-hot label to create a batch of labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CVBEvd1MzQ69",
    "outputId": "07fc1165-3e8e-4156-f18a-55bb0868f6cd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[208., 217., 160.],\n",
       "         [215., 227., 155.],\n",
       "         [216., 228., 144.],\n",
       "         ...,\n",
       "         [109., 150., 142.],\n",
       "         [115., 156., 148.],\n",
       "         [108., 149., 145.]],\n",
       "\n",
       "        [[216., 226., 165.],\n",
       "         [215., 225., 152.],\n",
       "         [224., 236., 152.],\n",
       "         ...,\n",
       "         [164., 201., 209.],\n",
       "         [169., 204., 210.],\n",
       "         [154., 189., 195.]],\n",
       "\n",
       "        [[210., 221., 155.],\n",
       "         [213., 224., 148.],\n",
       "         [220., 234., 149.],\n",
       "         ...,\n",
       "         [180., 213., 228.],\n",
       "         [174., 211., 220.],\n",
       "         [168., 205., 213.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 92., 153., 112.],\n",
       "         [ 68., 122.,  60.],\n",
       "         [ 65., 115.,  56.],\n",
       "         ...,\n",
       "         [ 73., 141., 120.],\n",
       "         [ 74., 144., 120.],\n",
       "         [ 76., 146., 122.]],\n",
       "\n",
       "        [[ 94., 156., 117.],\n",
       "         [ 87., 143.,  82.],\n",
       "         [ 55., 107.,  45.],\n",
       "         ...,\n",
       "         [ 82., 156., 141.],\n",
       "         [ 91., 161., 150.],\n",
       "         [ 87., 157., 147.]],\n",
       "\n",
       "        [[ 95., 159., 122.],\n",
       "         [106., 163., 110.],\n",
       "         [ 27.,  82.,  17.],\n",
       "         ...,\n",
       "         [ 91., 162., 164.],\n",
       "         [ 81., 151., 149.],\n",
       "         [ 80., 151., 147.]]],\n",
       "\n",
       "\n",
       "       [[[ 81.,  99.,  73.],\n",
       "         [ 79.,  97.,  71.],\n",
       "         [ 75.,  95.,  68.],\n",
       "         ...,\n",
       "         [ 50.,  75.,  36.],\n",
       "         [ 50.,  75.,  36.],\n",
       "         [ 49.,  74.,  35.]],\n",
       "\n",
       "        [[ 80.,  98.,  72.],\n",
       "         [ 77.,  97.,  70.],\n",
       "         [ 75.,  95.,  68.],\n",
       "         ...,\n",
       "         [ 49.,  74.,  35.],\n",
       "         [ 49.,  74.,  35.],\n",
       "         [ 49.,  74.,  35.]],\n",
       "\n",
       "        [[ 77.,  97.,  69.],\n",
       "         [ 76.,  96.,  68.],\n",
       "         [ 75.,  95.,  67.],\n",
       "         ...,\n",
       "         [ 47.,  72.,  33.],\n",
       "         [ 48.,  73.,  34.],\n",
       "         [ 48.,  73.,  34.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 71., 100.,  56.],\n",
       "         [ 72., 101.,  57.],\n",
       "         [ 74., 102.,  61.],\n",
       "         ...,\n",
       "         [ 71.,  98.,  63.],\n",
       "         [ 72.,  99.,  64.],\n",
       "         [ 70.,  98.,  60.]],\n",
       "\n",
       "        [[ 71., 100.,  56.],\n",
       "         [ 72., 101.,  57.],\n",
       "         [ 74., 102.,  61.],\n",
       "         ...,\n",
       "         [ 69.,  96.,  61.],\n",
       "         [ 69.,  96.,  61.],\n",
       "         [ 68.,  96.,  58.]],\n",
       "\n",
       "        [[ 71., 100.,  56.],\n",
       "         [ 72., 101.,  57.],\n",
       "         [ 72., 100.,  59.],\n",
       "         ...,\n",
       "         [ 64.,  91.,  56.],\n",
       "         [ 65.,  92.,  57.],\n",
       "         [ 63.,  91.,  53.]]],\n",
       "\n",
       "\n",
       "       [[[208.,  44.,  97.],\n",
       "         [202.,  40.,  90.],\n",
       "         [200.,  42.,  90.],\n",
       "         ...,\n",
       "         [ 69., 135., 123.],\n",
       "         [ 73., 144., 130.],\n",
       "         [ 78., 144., 132.]],\n",
       "\n",
       "        [[203.,  42.,  94.],\n",
       "         [200.,  42.,  91.],\n",
       "         [194.,  41.,  88.],\n",
       "         ...,\n",
       "         [ 71., 139., 128.],\n",
       "         [ 69., 140., 126.],\n",
       "         [ 68., 134., 122.]],\n",
       "\n",
       "        [[200.,  41.,  95.],\n",
       "         [199.,  42.,  93.],\n",
       "         [190.,  38.,  85.],\n",
       "         ...,\n",
       "         [ 68., 136., 125.],\n",
       "         [ 63., 133., 122.],\n",
       "         [ 63., 126., 115.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 61., 116.,  85.],\n",
       "         [ 61., 116.,  85.],\n",
       "         [ 51., 101.,  74.],\n",
       "         ...,\n",
       "         [ 91.,  27.,  41.],\n",
       "         [ 97.,  31.,  43.],\n",
       "         [ 99.,  31.,  44.]],\n",
       "\n",
       "        [[ 60., 113.,  83.],\n",
       "         [ 64., 119.,  88.],\n",
       "         [ 55., 105.,  78.],\n",
       "         ...,\n",
       "         [ 84.,  34.,  43.],\n",
       "         [ 88.,  26.,  39.],\n",
       "         [ 95.,  29.,  43.]],\n",
       "\n",
       "        [[ 48., 101.,  73.],\n",
       "         [ 62., 117.,  88.],\n",
       "         [ 66., 119.,  93.],\n",
       "         ...,\n",
       "         [ 71.,  66.,  62.],\n",
       "         [ 78.,  35.,  44.],\n",
       "         [ 90.,  36.,  49.]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[218., 202., 187.],\n",
       "         [193., 185., 172.],\n",
       "         [173., 170., 153.],\n",
       "         ...,\n",
       "         [204., 173., 126.],\n",
       "         [195., 166., 122.],\n",
       "         [195., 170., 130.]],\n",
       "\n",
       "        [[220., 204., 189.],\n",
       "         [194., 187., 171.],\n",
       "         [175., 169., 153.],\n",
       "         ...,\n",
       "         [202., 171., 124.],\n",
       "         [193., 164., 120.],\n",
       "         [191., 168., 127.]],\n",
       "\n",
       "        [[219., 203., 187.],\n",
       "         [192., 185., 169.],\n",
       "         [173., 167., 151.],\n",
       "         ...,\n",
       "         [201., 170., 123.],\n",
       "         [191., 164., 119.],\n",
       "         [188., 167., 124.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 50.,  49.,  31.],\n",
       "         [ 67.,  62.,  43.],\n",
       "         [ 69.,  66.,  49.],\n",
       "         ...,\n",
       "         [160., 146.,  99.],\n",
       "         [171., 154., 102.],\n",
       "         [187., 163., 115.]],\n",
       "\n",
       "        [[ 50.,  49.,  31.],\n",
       "         [ 67.,  62.,  43.],\n",
       "         [ 68.,  65.,  48.],\n",
       "         ...,\n",
       "         [155., 141.,  96.],\n",
       "         [169., 151., 101.],\n",
       "         [183., 159., 113.]],\n",
       "\n",
       "        [[ 50.,  49.,  31.],\n",
       "         [ 66.,  61.,  42.],\n",
       "         [ 67.,  64.,  47.],\n",
       "         ...,\n",
       "         [150., 133.,  89.],\n",
       "         [166., 148.,  98.],\n",
       "         [181., 157., 111.]]],\n",
       "\n",
       "\n",
       "       [[[137., 136., 116.],\n",
       "         [134., 132., 117.],\n",
       "         [130., 128., 116.],\n",
       "         ...,\n",
       "         [164., 169., 147.],\n",
       "         [166., 171., 149.],\n",
       "         [153., 161., 138.]],\n",
       "\n",
       "        [[135., 136., 118.],\n",
       "         [122., 123., 109.],\n",
       "         [116., 113., 104.],\n",
       "         ...,\n",
       "         [182., 187., 165.],\n",
       "         [137., 145., 122.],\n",
       "         [129., 139., 115.]],\n",
       "\n",
       "        [[130., 132., 119.],\n",
       "         [113., 115., 104.],\n",
       "         [105., 104.,  99.],\n",
       "         ...,\n",
       "         [145., 153., 132.],\n",
       "         [126., 135., 114.],\n",
       "         [126., 138., 116.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 29.,  10.,  40.],\n",
       "         [ 28.,   9.,  37.],\n",
       "         [ 26.,  10.,  37.],\n",
       "         ...,\n",
       "         [ 52.,  24.,  85.],\n",
       "         [ 52.,  24.,  85.],\n",
       "         [ 55.,  27.,  88.]],\n",
       "\n",
       "        [[ 28.,   9.,  39.],\n",
       "         [ 26.,   7.,  35.],\n",
       "         [ 24.,   8.,  35.],\n",
       "         ...,\n",
       "         [ 53.,  25.,  86.],\n",
       "         [ 52.,  24.,  85.],\n",
       "         [ 52.,  24.,  85.]],\n",
       "\n",
       "        [[ 25.,   9.,  36.],\n",
       "         [ 22.,   6.,  33.],\n",
       "         [ 23.,   7.,  34.],\n",
       "         ...,\n",
       "         [ 53.,  25.,  86.],\n",
       "         [ 50.,  22.,  83.],\n",
       "         [ 50.,  22.,  83.]]],\n",
       "\n",
       "\n",
       "       [[[120., 121., 115.],\n",
       "         [120., 121., 113.],\n",
       "         [117., 119., 108.],\n",
       "         ...,\n",
       "         [106.,  11.,   0.],\n",
       "         [ 97.,   8.,   0.],\n",
       "         [ 93.,   5.,   0.]],\n",
       "\n",
       "        [[124., 125., 117.],\n",
       "         [121., 122., 114.],\n",
       "         [120., 122., 111.],\n",
       "         ...,\n",
       "         [127.,  30.,  11.],\n",
       "         [120.,  27.,   9.],\n",
       "         [114.,  21.,   4.]],\n",
       "\n",
       "        [[125., 126., 118.],\n",
       "         [120., 121., 113.],\n",
       "         [120., 122., 111.],\n",
       "         ...,\n",
       "         [138.,  39.,  18.],\n",
       "         [133.,  36.,  17.],\n",
       "         [126.,  29.,  12.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[  1.,   6.,   0.],\n",
       "         [  2.,   7.,   0.],\n",
       "         [  0.,   5.,   0.],\n",
       "         ...,\n",
       "         [116.,  26.,   2.],\n",
       "         [109.,  22.,   2.],\n",
       "         [108.,  23.,   2.]],\n",
       "\n",
       "        [[  1.,   6.,   0.],\n",
       "         [  2.,   7.,   0.],\n",
       "         [  0.,   5.,   0.],\n",
       "         ...,\n",
       "         [115.,  25.,   1.],\n",
       "         [105.,  18.,   0.],\n",
       "         [105.,  20.,   0.]],\n",
       "\n",
       "        [[  1.,   6.,   0.],\n",
       "         [  0.,   5.,   0.],\n",
       "         [  0.,   5.,   0.],\n",
       "         ...,\n",
       "         [107.,  17.,   0.],\n",
       "         [108.,  20.,   0.],\n",
       "         [103.,  18.,   0.]]]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_img_holder.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gde0f41oqmPr"
   },
   "source": [
    "Now test data is in numpy format with standardized dimension, pixel value between 0 and 255, and batched. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PhtWkshWr1Wh"
   },
   "source": [
    "### Mapping prediction to class name\n",
    "I need to create a reverse lookup dictionary to map probability back to label. In other words, I want to find the index where maximum probability is positioned in the array. Map this position index to flower type. To create the lookup dictionary, I need to parse the TFRecord with feature descriptions to extract label indices and names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "-JDlxmv8r5I-"
   },
   "outputs": [],
   "source": [
    "feature_description = {\n",
    "    'image/channels' :  tf.io.FixedLenFeature([], tf.int64),\n",
    "    'image/class/label' :  tf.io.FixedLenFeature([], tf.int64),\n",
    "    'image/class/text' : tf.io.FixedLenFeature([], tf.string),\n",
    "    'image/colorspace' : tf.io.FixedLenFeature([], tf.string),\n",
    "    'image/encoded' : tf.io.FixedLenFeature([], tf.string),\n",
    "    'image/filename' : tf.io.FixedLenFeature([], tf.string),\n",
    "    'image/format' : tf.io.FixedLenFeature([], tf.string),\n",
    "    'image/height' : tf.io.FixedLenFeature([], tf.int64),\n",
    "    'image/width' : tf.io.FixedLenFeature([], tf.int64)\n",
    "}\n",
    "\n",
    "def _parse_function(example_proto):\n",
    "  return tf.io.parse_single_example(example_proto, feature_description)\n",
    "\n",
    "parsd_ds = test_all_ds.map(_parse_function)\n",
    "\n",
    "val_label_map = {}\n",
    "# getting label mapping\n",
    "for image_features in parsd_ds.take(30):\n",
    "    label_idx = image_features['image/class/label'].numpy()\n",
    "    label_str = image_features['image/class/text'].numpy().decode()\n",
    "    if label_idx not in val_label_map:\n",
    "        val_label_map[label_idx] = label_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nNYPhum7sDPR",
    "outputId": "142d24be-b09a-4027-cba6-037d6b88add0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{4: 'tulips', 3: 'dandelion', 1: 'sunflowers', 2: 'daisy', 0: 'roses'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "sW_xt1I42zQ3"
   },
   "outputs": [],
   "source": [
    "actual = []\n",
    "for i in range(len(np_lbl_holder)):\n",
    "    class_key = np.argmax(np_lbl_holder[i])\n",
    "    actual.append(val_label_map.get(class_key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`actual` is a list that contains the true labels for test image in the same order as the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iz1uCxPUqvqm"
   },
   "source": [
    "### Scoring batch images with integer quantization model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "5FIU2fhRqRJG"
   },
   "outputs": [],
   "source": [
    "def lookup(np_entry, dictionary):\n",
    "    class_key = np.argmax(np_entry)\n",
    "    return dictionary.get(class_key)\n",
    "    \n",
    "def batch_predict(input_raw, input_tensor, output_tensor, dictionary):\n",
    "    input_data = np.array(np.expand_dims(input_raw, axis=0), dtype=np.uint8)\n",
    "    interpreter.set_tensor(input_tensor['index'], input_data)\n",
    "    interpreter.invoke()\n",
    "    interpreter_output = interpreter.get_tensor(output_tensor['index'])\n",
    "    plain_text_label = lookup(interpreter_output, dictionary)\n",
    "    return plain_text_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rdaTdTdurat9"
   },
   "source": [
    "### Load quantized model\n",
    "Earlier, we encoded the path to the quantized model in `tgt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OvYtmYqFselx",
    "outputId": "e5bb4de2-69fc-4c32-dbb4-965135ec817c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('../train_base_model/tf_datasets/flower_photos/quantized_resnet_vector/tflite_int8_model/converted_model_reduced.tflite')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "PFpHBivSrds3"
   },
   "outputs": [],
   "source": [
    "##Load the TFLite model and allocate tensors.\n",
    "## tgt is the pathlib object referring to file path and <TFLITE_MODEL_NAME>.tflite\n",
    "interpreter = tf.lite.Interpreter(model_path=str(tgt))\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "77QLlmLVrf7e"
   },
   "outputs": [],
   "source": [
    "# Get input and output tensors.\n",
    "input_details = interpreter.get_input_details()[0]\n",
    "output_details = interpreter.get_output_details()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_DdEDG6ysHnl",
    "outputId": "c490d2b9-5c5a-4575-8a0c-4e559a15803f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'input_1',\n",
       " 'index': 270,\n",
       " 'shape': array([  1, 224, 224,   3], dtype=int32),\n",
       " 'shape_signature': array([ -1, 224, 224,   3], dtype=int32),\n",
       " 'dtype': numpy.uint8,\n",
       " 'quantization': (0.0058823530562222, 0),\n",
       " 'quantization_parameters': {'scales': array([0.00588235], dtype=float32),\n",
       "  'zero_points': array([0], dtype=int32),\n",
       "  'quantized_dimension': 0},\n",
       " 'sparsity_parameters': {}}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5i1GuLsDtU1_",
    "outputId": "b21b73ca-120f-4aca-961d-12980b7227e0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Identity',\n",
       " 'index': 271,\n",
       " 'shape': array([1, 5], dtype=int32),\n",
       " 'shape_signature': array([-1,  5], dtype=int32),\n",
       " 'dtype': numpy.uint8,\n",
       " 'quantization': (0.00390625, 0),\n",
       " 'quantization_parameters': {'scales': array([0.00390625], dtype=float32),\n",
       "  'zero_points': array([0], dtype=int32),\n",
       "  'quantized_dimension': 0},\n",
       " 'sparsity_parameters': {}}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "c66lY4VquWaa"
   },
   "outputs": [],
   "source": [
    "# Test the model\n",
    "input_data = np.array(np.expand_dims(np_img_holder[0], axis=0), dtype=np.uint8)\n",
    "interpreter.set_tensor(input_details['index'], input_data)\n",
    "interpreter.invoke()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vNgpMgXbrHyv",
    "outputId": "68e6d8b2-5e0b-4036-88d7-ac6429059181"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tulips\n",
      "1 dandelion\n",
      "2 tulips\n",
      "3 sunflowers\n",
      "4 daisy\n",
      "5 dandelion\n",
      "6 dandelion\n",
      "7 roses\n",
      "8 dandelion\n",
      "9 tulips\n",
      "10 dandelion\n",
      "11 roses\n",
      "12 dandelion\n",
      "13 tulips\n",
      "14 roses\n",
      "15 sunflowers\n",
      "16 daisy\n",
      "17 dandelion\n",
      "18 sunflowers\n",
      "19 daisy\n",
      "20 roses\n",
      "21 roses\n",
      "22 dandelion\n",
      "23 sunflowers\n",
      "24 roses\n",
      "25 tulips\n",
      "26 tulips\n",
      "27 tulips\n",
      "28 dandelion\n",
      "29 roses\n",
      "30 roses\n",
      "31 daisy\n",
      "32 sunflowers\n",
      "33 sunflowers\n",
      "34 tulips\n",
      "35 dandelion\n",
      "36 daisy\n",
      "37 daisy\n",
      "38 roses\n",
      "39 sunflowers\n",
      "40 roses\n",
      "41 dandelion\n",
      "42 daisy\n",
      "43 roses\n",
      "44 sunflowers\n",
      "45 daisy\n",
      "46 daisy\n",
      "47 roses\n",
      "48 daisy\n",
      "49 roses\n"
     ]
    }
   ],
   "source": [
    "batch_quantized_prediction = []\n",
    "for i in range(sample_size):\n",
    "    plain_text_label = batch_predict(np_img_holder[i], input_details, output_details, val_label_map)\n",
    "    batch_quantized_prediction.append(plain_text_label)\n",
    "    print(i, plain_text_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "53aK_Ll729Kv",
    "outputId": "9df50c44-be07-4dc4-e73d-ae3f8b2a212b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tulips',\n",
       " 'dandelion',\n",
       " 'tulips',\n",
       " 'sunflowers',\n",
       " 'daisy',\n",
       " 'dandelion',\n",
       " 'dandelion',\n",
       " 'roses',\n",
       " 'dandelion',\n",
       " 'tulips',\n",
       " 'dandelion',\n",
       " 'roses',\n",
       " 'dandelion',\n",
       " 'tulips',\n",
       " 'roses',\n",
       " 'sunflowers',\n",
       " 'daisy',\n",
       " 'dandelion',\n",
       " 'sunflowers',\n",
       " 'daisy',\n",
       " 'roses',\n",
       " 'roses',\n",
       " 'dandelion',\n",
       " 'sunflowers',\n",
       " 'roses',\n",
       " 'tulips',\n",
       " 'tulips',\n",
       " 'tulips',\n",
       " 'dandelion',\n",
       " 'roses',\n",
       " 'roses',\n",
       " 'daisy',\n",
       " 'sunflowers',\n",
       " 'sunflowers',\n",
       " 'tulips',\n",
       " 'dandelion',\n",
       " 'daisy',\n",
       " 'daisy',\n",
       " 'roses',\n",
       " 'sunflowers',\n",
       " 'roses',\n",
       " 'dandelion',\n",
       " 'daisy',\n",
       " 'roses',\n",
       " 'sunflowers',\n",
       " 'daisy',\n",
       " 'daisy',\n",
       " 'roses',\n",
       " 'daisy',\n",
       " 'roses']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_quantized_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tulips',\n",
       " 'dandelion',\n",
       " 'tulips',\n",
       " 'sunflowers',\n",
       " 'daisy',\n",
       " 'sunflowers',\n",
       " 'daisy',\n",
       " 'roses',\n",
       " 'dandelion',\n",
       " 'tulips',\n",
       " 'dandelion',\n",
       " 'tulips',\n",
       " 'dandelion',\n",
       " 'roses',\n",
       " 'roses',\n",
       " 'sunflowers',\n",
       " 'daisy',\n",
       " 'dandelion',\n",
       " 'sunflowers',\n",
       " 'tulips',\n",
       " 'tulips',\n",
       " 'roses',\n",
       " 'dandelion',\n",
       " 'sunflowers',\n",
       " 'roses',\n",
       " 'tulips',\n",
       " 'tulips',\n",
       " 'tulips',\n",
       " 'dandelion',\n",
       " 'roses',\n",
       " 'sunflowers',\n",
       " 'daisy',\n",
       " 'sunflowers',\n",
       " 'sunflowers',\n",
       " 'dandelion',\n",
       " 'dandelion',\n",
       " 'daisy',\n",
       " 'daisy',\n",
       " 'roses',\n",
       " 'sunflowers',\n",
       " 'roses',\n",
       " 'dandelion',\n",
       " 'daisy',\n",
       " 'roses',\n",
       " 'sunflowers',\n",
       " 'daisy',\n",
       " 'daisy',\n",
       " 'roses',\n",
       " 'daisy',\n",
       " 'tulips']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o3jQeInUrJ3t",
    "outputId": "d1c033ea-2d74-4357-daa9-3a94b95a1a31"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(actual, batch_quantized_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e76H1woL21U-"
   },
   "source": [
    "We also made a comparison between the truth and prediction. Results may vary for re-training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "V2_50_4_Integer_Quantization_Colab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
